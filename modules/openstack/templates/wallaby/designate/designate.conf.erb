[DEFAULT]
# Where an option is commented out, but filled in this shows the default
# value of that option

########################
## General Configuration
########################

use_syslog = True
syslog_log_facility = LOG_LOCAL0

# set the usgi loglevel to 'WARN' to filter out haproxy pings
default_log_levels = amqp=WARN,amqplib=WARN,boto=WARN,qpid=WARN,sqlalchemy=WARN,suds=INFO,oslo.messaging=INFO,oslo_messaging=INFO,iso8601=WARN,requests.packages.urllib3.connectionpool=WARN,urllib3.connectionpool=WARN,websocket=WARN,requests.packages.urllib3.util.retry=WARN,urllib3.util.retry=WARN,keystonemiddleware=WARN,routes.middleware=WARN,stevedore=WARN,taskflow=WARN,keystoneauth=WARN,oslo.cache=INFO,oslo_policy=INFO,dogpile.core.dogpile=INFO,eventlet.wsgi.server=WARN,kazoo.client=WARN,keystone=INFO,oslo_service.loopingcall=WARN

# Show debugging output in logs (sets DEBUG log level output)
#debug = false

transport_url = rabbit://<%= @rabbitmq_nodes.map{ |rabbit_host| "#{@rabbit_user}:#{@rabbit_pass}\@#{rabbit_host}:5671" }.join(',') %>

# Top-level directory for maintaining designate's state
state_path = /var/lib/designate

# Log Configuration
#log_config = None

# Log directory
log_dir = /var/log/designate

# Use "sudo designate-rootwrap /etc/designate/rootwrap.conf" to use the real
# root filter facility.
# Change to "sudo" to skip the filtering and just run the comand directly
root_helper = sudo designate-rootwrap /etc/designate/rootwrap.conf

# Which networking API to use, Defaults to neutron
#network_api = neutron

# we have a lot of instances, so raise quotas:
quota_zones = 25
quota_zone_recordsets = 10000
quota_zone_records = 10000
quota_recordset_records = 20
quota_api_export_size = 10000

# These are used in Liberty but are (I think) deprecated in future versions.
quota_domain_records = 10000
quota_domain_recordsets = 10000

########################
## Service Configuration
########################
#-----------------------
# Central Service
#-----------------------
[service:central]
# Maximum domain name length
max_domain_name_len = 255

# Maximum record name length
max_recordset_name_len = 255

# Minimum TTL
#min_ttl = None

## Managed resources settings

# Email to use for managed resources like domains created by the FloatingIP API
#managed_resource_email = root@example.io.

# Tenant ID to own all managed resources - like auto-created records etc.
#managed_resource_tenant_id = 123456

#-----------------------
# API Service
#-----------------------
[service:api]
# Authentication strategy to use - can be either "noauth" or "keystone"
auth_strategy = keystone

# Enable Version 1 API
enable_api_v1 = True

# Enable Version 2 API
enable_api_v2 = True

enable_host_header = True

api_base_uri=https://<%= @keystone_api_fqdn -%>:29001/

# Show the pecan HTML based debug interface (v2 only)
# This is only useful for development, and WILL break python-designateclient
# if an error occurs
#pecan_debug = False

# Enabled API Version 1 extensions
# Can be one or more of : diagnostics, quotas, reports, sync, touch
enabled_extensions_v1 = quotas, reports, sync

# Enabled API Version 2 extensions
# Can be one or more of : reports, quotas
enabled_extensions_v2 = quotas, reports

# Default per-page limit for the V2 API, a value of None means show all results
# by default.  We need to override because the default is a miserly '20'
default_limit_v2 = 10000

# Max page size in the V2 API
#max_limit_v2 = 1000

# Enable Admin API (experimental)
#enable_api_admin = False

# Enabled Admin API extensions
# Can be one or more of : reports, quotas, counts, tenants, target_sync
# zone export is in zones extension
#enabled_extensions_admin =

# Default per-page limit for the Admin API, a value of None means show all results
# by default.  We need to override because the default is a miserly '20'
default_limit_admin = 10000

# Max page size in the Admin API
#max_limit_admin = 1000


#-----------------------
# Keystone Middleware
#-----------------------
[keystone_authtoken]
auth_type = password
www_authenticate_uri = <%= @keystone_public_uri %>
auth_url = <%= @keystone_admin_uri %>
password = <%= @ldap_user_pass %>
project_domain_id = default
project_name = admin
region_name = <%= @region %>
user_domain_id = default
username = novaadmin
# We want this but need to figure out about service roles first
#service_token_roles_required = True

#-----------------------
# Sink Service
#-----------------------
[service:sink]
# List of notification handlers to enable, configuration of these needs to
# correspond to a [handler:my_driver] section below or else in the config
# Can be one or more of : nova_fixed, neutron_floatingip
enabled_notification_handlers = nova_fixed_multi, wmf_sink

#-----------------------
# mDNS Service
#-----------------------
[service:mdns]
#workers = None
#tcp_backlog = 100

# Setting this allows us to listen on ipv6 as well as ipv4
listen = [::0]:5354

#-----------------------
# Agent Service
#-----------------------
[service:agent]
#workers = None
#host = 0.0.0.0
#port = 5358
#tcp_backlog = 100
#allow_notify = 127.0.0.1
#masters = 127.0.0.1:5354
#backend_driver = fake


##############
## Network API
##############
#[network_api:neutron]
# Comma separated list of values, formatted "<name>|<neutron_uri>"
#endpoints = RegionOne|http://localhost:9696
#endpoint_type = publicURL
#timeout = 30
#admin_username = designate
#admin_password = designate
#admin_tenant_name = designate
#auth_url = https://localhost:25357/v2.0
#insecure = False
#auth_strategy = keystone
#ca_certificates_file =

########################
## Storage Configuration
########################
#-----------------------
# SQLAlchemy Storage
#-----------------------
[storage:sqlalchemy]
# Database connection string - to configure options for a given implementation
# like sqlalchemy or other see below
connection = mysql+pymysql://<%= @db_user %>:<%= @db_pass %>@<%= @db_host %>/<%= @db_name %>
#connection_debug = 100
#connection_trace = True
idle_timeout = 3600
max_retries = 10
retry_interval = 10

########################
## Handler Configuration
########################
#-----------------------
# Nova Fixed Multi Handler
#-----------------------
[handler:nova_fixed_multi]
# Domain ID of domain to create records in. For a pre-existing domain,
#  in this case eqiad1.wikimedia.cloud
domain_id = '<%= @domain_id_internal_forward %>'
legacy_domain_id = '<%= @domain_id_internal_forward_legacy %>'
site = '<%= scope.lookupvar("::site") %>'
notification_topics = monitor
notification_topics = notifications
control_exchange = nova
format = '%(hostname)s.%(project_name)s.%(zone)s'
reverse_domain_id = '<%= @domain_id_internal_reverse %>'
reverse_format = '%(hostname)s.%(project_name)s.%(zone)s'

#-----------------------
# WMF-specific handler to clean up after instance deletion
#
#  this deletes puppet certs for the deleted instance.
#-----------------------
[handler:wmf_sink]
# Domain ID of domain for instances.
#  For a pre-existing domain, in this case eqiad1.wikimedia.cloud
domain_id = '<%= @domain_id_internal_forward %>'
legacy_domain_id = '<%= @domain_id_internal_forward_legacy %>'
notification_topics = monitor
notification_topics = notifications
control_exchange = nova

certmanager_user = certmanager
fqdn_format = '%(hostname)s.%(project_name)s.%(zone)s'
puppet_master_host = "<%= @puppetmaster_hostname_ip %>"

# This is the region that the proxy endpoint lives in:
region = "<%= @region %>"

# For managing the instance-puppet git repo
puppet_git_repo_url = "ssh://<%= @puppet_git_repo_user %>@gerrit.wikimedia.org:29418/cloud/<%= @puppet_git_repo_name %>"
puppet_git_repo_user = "<%= @puppet_git_repo_user %>"
puppet_git_repo_key_path = "<%= @puppet_git_repo_key_path %>"

#------------------------
# Neutron Floating Handler
#------------------------
[handler:neutron_floatingip]
# Domain ID of domain to create records in. Should be pre-created
#domain_id =
#notification_topics = notifications
#control_exchange = 'neutron'
#format = '%(octet0)s-%(octet1)s-%(octet2)s-%(octet3)s.%(domain)s'

[oslo_messaging_rabbit]
rabbit_retry_interval=1
rabbit_retry_backoff=2
rabbit_durable_queues=true
rabbit_ha_queues=true

ssl = True
ssl_ca_file = /etc/ssl/certs/wmf-ca-certificates.crt
ssl_version = TLSv1_2

[oslo_messaging_notifications]
driver = messagingv2
topics = notifications

[coordination]
# The backend URL to use for distributed coordination. If unset services that
# need coordination will function as a standalone service. This is a `tooz` url
# - see https://docs.openstack.org/tooz/latest/user/compatibility.html (string
# value)
#
# Each designate host just talks to the local mcrouter instance; this instance
# is part of a pool that includes the other designate hosts.
#
backend_url = memcached://localhost:11213

[oslo_policy]
policy_file = policy.yaml

[service:worker]
#workers = None
#threads = 1000
#threshold_percentage = 100
#poll_timeout = 30
#poll_retry_interval = 15
#poll_max_retries = 10
#poll_delay = 5

notify = True

[service:producer]
#workers = None
#threads = 1000
# Can be any/all of: periodic_exists, delayed_notify, worker_periodic_recovery
# None => All tasks enabled
#enabled_tasks = None

[producer_task:domain_purge]
#interval = 3600  # 1h
#batch_size = 100
#time_threshold = 604800  # 7 days

[producer_task:delayed_notify]
#interval = 5

[producer_task:worker_periodic_recovery]
#interval = 120
