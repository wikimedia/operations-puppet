[DEFAULT]

verbose=False
auth_strategy=keystone
compute_driver=nova.virt.libvirt.LibvirtDriver
notification_topics=notifications,ceilometer_notifications
connection_type=libvirt
root_helper=sudo nova-rootwrap /etc/nova/rootwrap.conf
instance_name_template=i-%08x
daemonize=1
scheduler_driver=nova.scheduler.filter_scheduler.FilterScheduler
wmf_scheduler_hosts_pool=<%= @novaconfig["scheduler_pool"].join(",") %>
scheduler_default_filters=RetryFilter,AvailabilityZoneFilter,RamFilter,ComputeFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter,AggregateInstanceExtraSpecsFilter,AvailabilityZoneFilter,SchedulerPoolFilter,DiskFilter

# Turn off ec2 APIs
enabled_apis=osapi_compute, metadata

# Don't allow duplicate instance names
osapi_compute_unique_server_name_scope='global'

# Security groups for big projects (e.g. tools) are too hard to
#  organize and cause a timeout between conductor and compute.
# This is /maybe/ fixed in mitaka, so we can investigate reverting
#  this to 60 (the proper default) in future versions.
rpc_response_timeout=180

my_ip=<%= @novaconfig["my_ip"] %>
log_dir=/var/log/nova
state_path=/var/lib/nova
image_service=nova.image.glance.GlanceImageService
remove_unused_base_images=True
s3_host=<%= @novaconfig["glance_host"] %>
glance_api_servers=<%= @novaconfig["glance_host"] %>:9292
cc_host=<%= @novaconfig["cc_host"] %>
ec2_url=http://<%= @novaconfig["api_host"] %>:8773/services/Cloud
ec2_dmz_host=<%= @novaconfig["api_ip"] %>
dmz_cidr=<%= @novaconfig["dmz_cidr"] %>
dhcpbridge_flagfile=/etc/nova/nova.conf
dhcpbridge=/usr/bin/nova-dhcpbridge
dhcp_domain=<%= @novaconfig["dhcp_domain"] %>

# Default quotas for new projects:  1 xlarge instance
#  (or 4 medium, or 8 small)
quota_cores = 8
quota_instances = 8
quota_ram = 16384
quota_floating_ips=<%= @novaconfig["quota_floating_ips"] %>
quota_fixed_ips=200

# Quota drift is a common problem
max_age = 30


api_paste_config=/etc/nova/api-paste.ini
#use_ipv6=True
allow_same_net_traffic=False
force_dhcp_release=True
# set the lease time to 24 hours
dhcp_lease_time=86400
# timeout expired leases after 48 hours
fixed_ip_disassociate_timeout=172800
iscsi_helper=tgtadm

network_api_class=nova.network.api.API
flat_network_dhcp_start=<%= @novaconfig["dhcp_start"] %>
network_manager=nova.network.manager.FlatDHCPManager
flat_interface=<%= @novaconfig["network_flat_interface"] %>
flat_injected=False
flat_network_bridge=<%= @novaconfig["flat_network_bridge"] %>
fixed_range=<%= @novaconfig["fixed_range"] %>
public_interface=<%= @novaconfig["network_public_interface"] %>
routing_source_ip=<%= @novaconfig["network_public_ip"] %>
multi_host=False

dnsmasq_config_file=/etc/dnsmasq-nova.conf

# Settings for wikistatus, the plugin that updates OSM with instance status:
notification_driver=wikistatus
notify_on_state_change=vm_state

wiki_host=<%= @wikitechstatusconfig["host"] %>
wiki_domain=<%= @wikitechstatusconfig["domain"] %>
wiki_page_prefix=<%= @wikitechstatusconfig["page_prefix"] %>
wiki_instance_region=<%= @wikitechstatusconfig["region"] %>
wiki_login=<%= @wikitechstatusconfig["user"] %>
wiki_password=<%= @wikitechstatusconfig["pass"] %>
wiki_instance_dns_domain=<%= @wikitechstatusconfig["dns_domain"] %>

# Designate things:
notification_driver = messagingv2

# Ceilometer things:
instance_usage_audit = True
instance_usage_audit_period = hour
notify_on_state_change = vm_and_task_state

# Overprovision settings

# Running OOM on a compute host produces weird spontaneous shutdowns.
#  avoid overcommitting as long as we can afford it.
ram_allocation_ratio=1.0

# Since our images are copy-on-write we can support some overcommitting here.
disk_allocation_ratio=1.5


# Deprecated, remove in Kilo:
node_availability_zone=<%= @novaconfig["zone"] %>
zone_name=<%= @novaconfig["zone"] %>
# Should be:
#default_availability_zone = <%= @novaconfig["zone"] %>

[database]
# http://docs.sqlalchemy.org/en/latest/core/pooling.html
connection=mysql://<%= @novaconfig["db_user"] %>:<%= @novaconfig["db_pass"] %>@<%= @novaconfig["db_host"] %>/<%= @novaconfig["db_name"] %>
max_overflow = 25
max_pool_size = 10
pool_timeout = 60

[glance]
host=<%= @novaconfig["glance_host"] %>

[libvirt]
virt_type=<%= @novaconfig["libvirt_type"] %>
use_virtio_for_bridges=True
# live_migration_bandwidth is documented in the code, and nowhere else.
# 'Maximum bandwidth to be used during migration, in Mbps'
# Limit this to around a third of available 1Gbps connection so we don't
# throttle running instances when migrating.
live_migration_bandwidth=300
live_migration_uri=<%= @novaconfig["live_migration_uri"] %>

[oslo_messaging_rabbit]
rabbit_host=<%= @novaconfig["rabbit_host"] %>
rabbit_port = 5672
rabbit_use_ssl = False
rabbit_userid = <%= @novaconfig["rabbit_user"] %>
rabbit_password = <%= @novaconfig["rabbit_pass"] %>

[oslo_concurrency]
lock_path=/var/lock/nova

[vnc]
enabled=False

[spice]
html5proxy_host=<%= @novaconfig['controller_hostname'] %>
html5proxy_port=6082
html5proxy_base_url=https://<%= @novaconfig['spice_hostname'] %>/spice_sec_auto.html

# These two only matter on the compute hosts:
server_listen=0.0.0.0
server_proxyclient_address=<%= @novaconfig["my_ip"] %>

# Enable spice related features (boolean value)
enabled=True

# Enable spice guest agent support (boolean value)
agent_enabled=True

# Keymap for spice (string value)
keymap=en-us
