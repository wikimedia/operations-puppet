#!/bin/bash
### THIS FILE IS MANAGED BY PUPPET
### puppet:///modules/mediawiki_new/jobrunner/jobs-loop.sh.erb
#
# NAME
# jobs-loop.sh -- Continuously process a MediaWiki jobqueue
#
# SYNOPSIS
# jobs-loop.sh [-t timeout] [-v virtualmemory] [job_type]
#
# DESCRIPTION
# jobs-loop.sh is an infinite "while loop" used to call MediaWiki runJobs.php
# and eventually attempt to process any job enqueued. MediaWiki jobs are split
# into several types, by default jobs-loop.sh will:
#  - first attempt to run the priorized jobs
#  - proceed to run any default jobs
#
# MediaWiki configuration variable $wgJobTypesExcludedFromDefaultQueue is used
# to exclude some types from the default processing. Those excluded job types
# could be processed on dedicated boxes by running jobs-loop.sh using the
# job_type parameter.
#
# You will probably want to run this script under your webserver username.
#
# Example:
# // Process job queues:
# jobs-loop.sh
#
# // Process jobs of type `webVideoTranscode` with a maxtime of 4 hours
# jobs-loop.sh -t 14400 webVideoTranscode
#

# How long can low priority jobs be run until some high priority
# jobs should be checked for and run if they exist.
hpmaxdelay=120

# The maxtime parameter for runJobs.php for low priority jobs.
# The lower this value is, the less jobs of one wiki can hog attention
# from the jobs on other wikis, though more overhead is incurred.
# This should be lower than hpmaxdelay.
lpmaxtime=60

# How long can high priority jobs be run until some low priority
# jobs should be checked for and run if they exist.
lpmaxdelay=600

# The maxtime parameter for runJobs.php for high priority jobs.
# The lower this value is, the less jobs of one wiki/type can hog attention
# from jobs of another wiki/type, though more overhead is incurred.
# This should be lower than lpmaxdelay.
hpmaxtime=30

# The procs parameter to runJobs.php.
# Lower values keep the process pipeline fuller and lead to more
# even picking of jobs from wikis, though more overhead is incurred.
forkcount=2

# default total memory limit (in kb) for this process and its sub-processes
maxvirtualmemory=400000

# Whether to process the default queue. Will be the case if no job type
# was specified on the command line. Else we only want to process given types
dodefault=true

while getopts "t:v:" flag
do
	case $flag in
		t)
			maxtime=$OPTARG
			;;
		v)
			maxvirtualmemory=$OPTARG
			;;
	esac
done
shift $(($OPTIND - 1))

# Limit virtual memory
if [ "$maxvirtualmemory" -gt 0 ]; then
	ulimit -v $maxvirtualmemory
fi

# When killed, make sure we are also getting rid of the child jobs
# we have spawned.
trap 'kill %-; exit' SIGTERM

if [ -z "$1" ]; then
	echo "Starting default queue job runner"
	dodefault=true
	hptypes="sendMail enotifNotify uploadFromUrl MoodBarHTMLMailerJob ArticleFeedbackv5MailerJob RenderJob"
else
	echo "Starting type-specific job runner: $1"
	dodefault=false
	hptypes=$1
fi

# Limit the number of concurrent sub-processes by waiting until the
# number of immediate child processes is less than the allowed limit.
function waitForProcessPipeline() {
	local subprocscreate=0 # number of free process slots
	while [ "$subprocscreate" -le 0 ]; do
		# Note: ps counts itself so 1 is subtracted
		local subproccount=$((`ps --no-headers -o pid --ppid=$$ | wc -w` - 1))
		subprocscreate=$((<%= procs %>/forkcount - subproccount))
		if [ "$subprocscreate" -gt 0 ]; then
			break # another immediate child process can start
		else
			echo "Pipeline full ($subproccount immediate sub-processes)..."
			sleep 1 # reduce polling load
		fi
	done
}

# Starting the infinite loop of doom
cd `readlink -f /usr/local/apache/common/multiversion`
while [ 1 ]; do
	foundjobs=n

	# Do the prioritized job types...
	started=`date +%s` # UNIX timestamp
	morehpjobs=y
	while [[ "$morehpjobs" == "y" ]]; do
		waitForProcessPipeline

		morehpjobs=n
		res=(`php MWScript.php nextJobDB.php --wiki=aawiki --types="$hptypes"`)
		db=${res[0]}
		type=${res[1]}

		if [ "$?" -ne "0" ]; then
			echo "Could not determine the next wiki."
		elif [ -n "$db" -a -n "$type" ]; then
			echo "$db $type"
			nice -n 20 php MWScript.php runJobs.php --wiki="$db" --procs="$forkcount" --type="$type" --maxtime=$hpmaxtime &
			# Do not spend too much time on prioritized jobs
			timestamp=`date +%s` # UNIX timestamp
			if [ "$timestamp" -lt "$started" -o $(( timestamp-started )) -ge "$lpmaxdelay" ]; then
				break
			else
				morehpjobs=y
			fi
			foundjobs=y
		fi
	done

	if $dodefault; then
		# Do the unprioritized job types...
		started=`date +%s` # UNIX timestamp
		morelpjobs=y
		while [[ "$morelpjobs" == "y" ]]; do
			waitForProcessPipeline

			morelpjobs=n
			db=`php MWScript.php nextJobDB.php --wiki=aawiki`

			if [ "$?" -ne "0" ]; then
				echo "Could not determine the next wiki."
			elif [ -n "$db" ]; then
				echo "$db"
				nice -n 20 php MWScript.php runJobs.php --wiki="$db" --procs="$forkcount" --maxtime=$lpmaxtime &
				# Do not spend too much time on unprioritized jobs
				timestamp=`date +%s` # UNIX timestamp
				if [ "$timestamp" -lt "$started" -o $(( timestamp-started )) -ge "$hpmaxdelay" ]; then
					break
				else
					morelpjobs=y
				fi
				foundjobs=y
			fi
		done
	fi

	if [[ "$foundjobs" == "n" ]]; then
		echo "No jobs..."
		sleep 5 # reduce polling load
	fi
done
