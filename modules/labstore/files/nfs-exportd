#!/usr/bin/python3
#
#  Copyright © 2015 Marc-André Pelletier <mpelletier@wikimedia.org>
#  Copyright © 2015 Yuvi Panda <yuvipanda@gmail.com>
#
#  Permission to use, copy, modify, and/or distribute this software for any
#  purpose with or without fee is hereby granted, provided that the above
#  copyright notice and this permission notice appear in all copies.
#
#  THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
#  WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
#  MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
#  ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
#  WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
#  ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
#  OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
#
#
#  THIS FILE IS MANAGED BY PUPPET
#

from urllib.request import urlopen
import ipaddress
import argparse
import yaml
import json
import os
import time
import logging
import sys
import subprocess


# Volumes that need an entry in exports.d
VOLUMES_NEEDING_EXPORTS = ['project', 'home']


def is_valid_ipv4(ip):
    """
    Returns true if ip is a valid ipv4 address
    """
    try:
        ipaddress.IPv4Address(ip)
        return True
    except ipaddress.AddressValueError:
        return False


class Project:
    """ subtree_check -- allows mounting of subdirectories
        async -- io should be done asynchronously
        no_root_squash -- allow root in project instances
                          to be treated as root on mount
    """
    EXPORTS_TEMPLATE = '/exp/project/{name} ' + \
        '-rw,nohide,fsid=00000000000000000-{gid}-0000000000' + \
        ',subtree_check,async,no_root_squash ' + \
        '{instance_ips}'

    def __init__(self, name, gid, instance_ips, volumes):
        self.name = name
        self.instance_ips = instance_ips
        self.volumes = volumes
        self.gid = gid
        self.path = os.path.join('/exp/project/', name)

    def get_exports(self):
        return Project.EXPORTS_TEMPLATE.format(
            name=self.name,
            gid=self.gid,
            instance_ips=' '.join(self.instance_ips)
        )


def get_instance_ips(project):
    """
    Return a list of Instance internal IPs for a given project

    This uses the Wikitech API to fetch this data
    """
    url = ("https://wikitech.wikimedia.org/w/api.php" +
           "?action=query&list=novainstances&niproject=%s" +
           "&niregion=eqiad&format=json") % project
    try:
        data = json.loads(urlopen(url, timeout=15).read().decode('utf-8'))
    except:
        logging.exception('Error fetching instance ip list for project %s', project)
        sys.exit(1)

    ips = []
    if 'query' in data and 'novainstances' in data['query']:
        for instance in data['query']['novainstances']:
            # Only provide internal IPs!
            ips += [ip for ip in instance['ip']
                    if is_valid_ipv4(ip) and ip.startswith('10.')]
    return ips

def get_projects_with_nfs(mounts_config):
    """
    Get populated project objects that need NFS exports
    :param mounts_config: dict
    :returns: list
    """
    projects = []
    for name, config in mounts_config['private'].items():
        if 'mounts' in config:
            mounts = [k for k, v in config['mounts'].items()
                      if k in VOLUMES_NEEDING_EXPORTS and v]
            if len(mounts) == 0:
                # Skip project if it has no private mounts
                logging.debug('skipping exports for %s, no private mounts', name)
                continue
        else:
            continue
        project = Project(name, config['gid'], get_instance_ips(name), mounts)
        projects.append(project)
        logging.debug('project %s has %s instances',
                     name, len(project.instance_ips))

    # Validate that there are no duplicate gids
    gids = [p.gid for p in projects]
    if len(set(gids)) != len(gids):
        logging.error('duplicate GIDs found in project config, aborting')
        sys.exit(1)

    logging.info("found %s projects requiring private mounts", len(projects))
    return projects


def exportfs():
    """ translate on disk definitions into active NFS exports
    :warn: this can fail with 0 exit code
    """
    exportfs = [
        '/usr/bin/sudo',
        '/usr/sbin/exportfs',
        '-ra'
    ]

    logging.info(' '.join(exportfs))
    subprocess.check_call(exportfs)

def write_public_exports(public_exports, exports_d_path):
    """ output public export definitions
    :param public_exports: dict of defined exports
    """
    public_paths = []
    for name, content in public_exports.items():
        logging.debug('writing exports file for public export %s', name)
        path = os.path.join(exports_d_path, 'public_%s.exports' % name)
        with open(path, 'w') as f:
            f.write(content)
        public_paths.append(path)
    logging.info("found %s public NFS exports" % (len(public_paths)))
    return public_paths

def write_project_exports(mounts_config, exports_d_path):
    """ output project export definitions
    :param mounts_config: dict of defined exports
    """
    project_paths = []
    projects = get_projects_with_nfs(mounts_config)
    for project in projects:
        logging.debug('writing exports file for %s', project.name)
        path = os.path.join(exports_d_path, '%s.exports' % project.name)
        with open(path, 'w') as f:
            f.write(project.get_exports())
        project_paths.append(path)
    return project_paths


def main():
    argparser = argparse.ArgumentParser()

    argparser.add_argument(
        '--exports-d-path',
        default='/etc/exports.d/',
        help='Dir to write exports files to',
    )

    argparser.add_argument(
        '--config-path',
        default='/etc/nfs-mounts.yaml',
        help='Path to YAML file containing config of which exports to maintain',
    )

    argparser.add_argument(
        '--interval',
        type=int,
        default=0,
        help='Set interval to rerun at',
    )

    argparser.add_argument(
        '--debug',
        help='Turn on debug logging',
        action='store_true'
    )

    args = argparser.parse_args()

    logging.basicConfig(
        format='%(asctime)s %(levelname)s %(message)s',
        level=logging.DEBUG if args.debug else logging.INFO)

    if os.getuid() == 0:
        logging.error('Daemon started as root, exiting')
        sys.exit(1)

    while True:

        try:
            with open(args.config_path) as f:
                config = yaml.safe_load(f)
        except:
            logging.exception('Could not load projects config file from %s', args.config_path)
            sys.exit(1)

        exports_d_path = args.exports_d_path

        existing_exports = [
            os.path.join(exports_d_path, filename)
            for filename in os.listdir(exports_d_path)]

        public_paths = write_public_exports(config['public'], exports_d_path)
        project_paths = write_project_exports(config, exports_d_path)

        # compile list of entries in export_d path that are not defined in current config
        existing_wo_public = list(set(existing_exports) - set(public_paths))
        existing_wo_all = list(set(existing_wo_public) - set(project_paths))

        if existing_wo_all:
            for unmanaged_export in existing_wo_all:
                with open(unmanaged_export) as f:
                    logging.warning('deleting %s with contents: %s', unmanaged_export, f.read())
                os.remove(unmanaged_export)

        exportfs()

        if args.interval > 0:
            time.sleep(args.interval)
        else:
            break

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        pass
