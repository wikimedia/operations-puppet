#!/usr/bin/python3
#
#  Copyright © 2015 Marc-André Pelletier <mpelletier@wikimedia.org>
#  Copyright © 2015 Yuvi Panda <yuvipanda@gmail.com>
#
#  Permission to use, copy, modify, and/or distribute this software for any
#  purpose with or without fee is hereby granted, provided that the above
#  copyright notice and this permission notice appear in all copies.
#
#  THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
#  WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
#  MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
#  ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
#  WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
#  ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
#  OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
#
#
#  THIS FILE IS MANAGED BY PUPPET
#

import ipaddress
import argparse
import yaml
import os
import time
import logging
import sys
import subprocess

from keystoneclient.session import Session as KeystoneSession
from keystoneclient.auth.identity.v3 import Password as KeystonePassword

from novaclient import client as novaclient

# Volumes that need an entry in exports.d
VOLUMES_NEEDING_EXPORTS = ['project', 'home', 'tools-home', 'tools-project']


def is_valid_ipv4(ip):
    """
    Returns true if ip is a valid ipv4 address
    """
    try:
        ipaddress.IPv4Address(ip)
        return True
    except ipaddress.AddressValueError:
        return False


class Project:
    """ subtree_check -- allows mounting of subdirectories
        async -- io should be done asynchronously
        no_root_squash -- allow root in project instances
                          to be treated as root on mount
    """
    EXPORTS_TEMPLATE = '/exp/project/{name} ' + \
        '-rw,nohide,fsid=00000000000000000-{gid}-0000000000' + \
        ',subtree_check,async,no_root_squash ' + \
        '{instance_ips}'

    def __init__(self, name, gid, instance_ips, volumes):
        self.name = name
        self.instance_ips = instance_ips
        self.volumes = volumes
        self.gid = gid
        self.path = os.path.join('/exp/project/', name)

    def get_exports(self):
        return Project.EXPORTS_TEMPLATE.format(
            name=self.name,
            gid=self.gid,
            instance_ips=' '.join(self.instance_ips)
        )


def get_instance_ips(project, observer_pass):
    """
    Return a list of Instance internal IPs for a given project

    This uses the Wikitech API to fetch this data
    """
    client = novaclient.Client(
        "2.0",
        session=KeystoneSession(auth=KeystonePassword(
            auth_url="http://labcontrol1001.wikimedia.org:5000/v3",
            username="novaobserver",
            password=observer_pass,
            project_name=project,
            user_domain_name='default',
            project_domain_name='default'
        ))
    )
    ips = []
    for instance in client.servers.list():
        # Only provide internal IPs!
        ips += [
            str(ip['addr']) for ip in instance.addresses['public']
            if ip['OS-EXT-IPS:type'] == 'fixed' and is_valid_ipv4(ip)
        ]
    return ips

def get_projects_with_nfs(mounts_config, observer_pass):
    """
    Get populated project objects that need NFS exports
    :param mounts_config: dict
    :returns: list
    """
    projects = []
    for name, config in mounts_config['private'].items():
        if 'mounts' in config:
            mounts = [k for k, v in config['mounts'].items()
                      if k in VOLUMES_NEEDING_EXPORTS and v]
            if len(mounts) == 0:
                # Skip project if it has no private mounts
                logging.debug('skipping exports for %s, no private mounts', name)
                continue
        else:
            continue
        project = Project(name, config['gid'], get_instance_ips(name, observer_pass), mounts)
        projects.append(project)
        logging.debug('project %s has %s instances',
                     name, len(project.instance_ips))

    # Validate that there are no duplicate gids
    gids = [p.gid for p in projects]
    if len(set(gids)) != len(gids):
        logging.error('duplicate GIDs found in project config, aborting')
        sys.exit(1)

    logging.info("found %s projects requiring private mounts", len(projects))
    return projects


def exportfs():
    """ translate on disk definitions into active NFS exports
    :warn: this can fail with 0 exit code
    """
    exportfs = [
        '/usr/bin/sudo',
        '/usr/sbin/exportfs',
        '-ra'
    ]

    logging.info(' '.join(exportfs))
    subprocess.check_call(exportfs)

def write_public_exports(public_exports, exports_d_path):
    """ output public export definitions
    :param public_exports: dict of defined exports
    """
    public_paths = []
    for name, content in public_exports.items():
        logging.debug('writing exports file for public export %s', name)
        path = os.path.join(exports_d_path, 'public_%s.exports' % name)
        with open(path, 'w') as f:
            f.write(content)
        public_paths.append(path)
    logging.info("found %s public NFS exports" % (len(public_paths)))
    return public_paths

def write_project_exports(mounts_config, exports_d_path, observer_pass):
    """ output project export definitions
    :param mounts_config: dict of defined exports
    """
    project_paths = []
    projects = get_projects_with_nfs(mounts_config, observer_pass)
    for project in projects:
        logging.debug('writing exports file for %s', project.name)
        path = os.path.join(exports_d_path, '%s.exports' % project.name)
        with open(path, 'w') as f:
            f.write(project.get_exports())
        project_paths.append(path)
    return project_paths


def main():
    argparser = argparse.ArgumentParser()

    argparser.add_argument(
        '--exports-d-path',
        default='/etc/exports.d/',
        help='Dir to write exports files to',
    )

    argparser.add_argument(
        '--config-path',
        default='/etc/nfs-mounts.yaml',
        help='Path to YAML file containing config of which exports to maintain',
    )

    argparser.add_argument(
        '--observer-pass',
        required=True,
        help='Password for the OpenStack observer account',
    )

    argparser.add_argument(
        '--interval',
        type=int,
        default=0,
        help='Set interval to rerun at',
    )

    argparser.add_argument(
        '--debug',
        help='Turn on debug logging',
        action='store_true'
    )

    args = argparser.parse_args()

    logging.basicConfig(
        format='%(asctime)s %(levelname)s %(message)s',
        level=logging.DEBUG if args.debug else logging.INFO)

    if os.getuid() == 0:
        logging.error('Daemon started as root, exiting')
        sys.exit(1)

    while True:

        try:
            with open(args.config_path) as f:
                config = yaml.safe_load(f)
        except:
            logging.exception('Could not load projects config file from %s', args.config_path)
            sys.exit(1)

        exports_d_path = args.exports_d_path

        existing_exports = [
            os.path.join(exports_d_path, filename)
            for filename in os.listdir(exports_d_path)]

        public_paths = write_public_exports(config['public'], exports_d_path)
        project_paths = write_project_exports(config, exports_d_path, args.observer_pass)

        # compile list of entries in export_d path that are not defined in current config
        existing_wo_public = list(set(existing_exports) - set(public_paths))
        existing_wo_all = list(set(existing_wo_public) - set(project_paths))

        if existing_wo_all:
            for unmanaged_export in existing_wo_all:
                with open(unmanaged_export) as f:
                    logging.warning('deleting %s with contents: %s', unmanaged_export, f.read())
                os.remove(unmanaged_export)

        exportfs()

        if args.interval > 0:
            time.sleep(args.interval)
        else:
            break

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        pass
