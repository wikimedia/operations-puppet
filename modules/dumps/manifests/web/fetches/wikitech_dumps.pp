class dumps::web::fetches::wikitech_dumps(
    $url            = undef,
    $miscdatasetsdir = undef,
) {

    $wikitechdir = "${miscdatasetsdir}/wikitech"

    file { $wikitechdir:
        ensure => 'directory',
        owner  => 'root',
        group  => 'root',
        mode   => '0755',
    }

    $wget = '/usr/bin/wget'
    # don't get anything with query params
    $wgetreject = "--reject-regex '(.*)\\?(.*)'"
    $wgetargs = "-nv -e robots=off -k -nH --wait 30 -np -m ${url} -P ${wikitechdir}"
    # filter out any whines about missing timestamp for index.html
    # as well url download announcements and summary, we only care about anything else
    $filter = "2>&1  | grep -E -v '(turned off|URL:http|FINISHED|Total|Downloaded)'"
    # toss wikitech's autogenerated index.html files when done
    $cleanuphtml = "find ${wikitechdir} -name 'index.html*' -exec rm {} \\;"
    # remove dumps older than 90 days
    $cleanupold = "find ${wikitechdir} -type f -mtime +90 -exec rm {} \\;"

    cron { 'dumps-fetches-wikitech':
        ensure  => 'present',
        command => "${wget} ${wgetreject} ${wgetargs} ${filter}; ${cleanuphtml}; ${cleanupold}",
        user    => 'root',
        minute  => '20',
        hour    => '3',
    }
}
