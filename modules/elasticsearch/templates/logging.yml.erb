rootLogger: INFO, file<% if @send_logs_to_logstash %>, ship_to_logstash<% end %>
logger:
  # log action execution errors for easier debugging
  action: DEBUG

  # This is noisy and already filed upstream:
  # https://github.com/elasticsearch/elasticsearch/issues/4203
  action.admin.cluster.node.stats: INFO

  # If you need to know more about shard allocation you to set this to debug.
  # Trace seems to generate enough logs to slow down the process.
  # cluster: DEBUG

  # reduce the logging for aws, too much is logged under the default INFO
  com.amazonaws: WARN
  common.jna: DEBUG

  # gateway
  #gateway: DEBUG
  #index.gateway: DEBUG

  # peer shard recovery
  #indices.recovery: DEBUG

  # discovery
  #discovery: TRACE

  index.search.slowlog: TRACE, index_search_slow_log_file
  index.indexing.slowlog: INFO, index_indexing_slow_log_file

additivity:
  index.search.slowlog: false
  index.indexing.slowlog: false

appender:
  file:
    type: file
    file: ${path.logs}/${cluster.name}.log
    encoding: UTF-8
    append: true
    layout:
      type: pattern
      conversionPattern: "[%d{ISO8601}][%-5p][%-25c] %m%n"

  index_search_slow_log_file:
    type: file
    file: ${path.logs}/${cluster.name}_index_search_slowlog.log
    encoding: UTF-8
    append: true
    layout:
      type: pattern
      conversionPattern: "[%d{ISO8601}][%-5p][%-25c] %m%n"

  index_indexing_slow_log_file:
    type: file
    file: ${path.logs}/${cluster.name}_index_indexing_slowlog.log
    encoding: UTF-8
    append: true
    layout:
      type: pattern
      conversionPattern: "[%d{ISO8601}][%-5p][%-25c] %m%n"

  # ship_to_logstash needs to also be added to rootLogger to actually ship logs
  ship_to_logstash:
    type: biz.paluch.logging.gelf.log4j.GelfLogAppender
    host: "udp:<%= @graylog_host %>"
    port: <%= @graylog_port %>
    originHost: <%= @hostname %>
    facility: elasticsearch
    extractStackTrace: true
    threshold: DEBUG
