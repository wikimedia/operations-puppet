# This file is managed by Puppet!
// layer-common code for all clusters

import std;

# this is needed by geoip.inc.vcl and zero.inc.vcl, and in general is the only
#   way to sanely do Set-Cookie in the face of multiple independent cookies
#   being set from different code.
import header;

import directors;

include "errorpage.inc.vcl";


# ACLs

acl local_host {
	"127.0.0.1";
	"<%= @ipaddress %>"; // note this matches nginx proxy_pass for TLS
}

// external trusted proxies aren't allowed to set XCIP (via XFF) to wikimedia_nets
acl wikimedia_nets {
<% scope.lookupvar('::network::constants::all_networks_lo').each do |entry|
	subnet, mask = entry.split("/", 2)
-%>
	"<%= subnet %>"/<%= mask %>;
<% end -%>
}

// This is currently used in 2 places:
// 1) frontends: only wikimedia_trust can fake X-F-P
// 2) backends: port 3128 can only connect from wikimedia_trust
acl wikimedia_trust {
<% scope.lookupvar('::network::constants::all_networks_lo').each do |entry|
	subnet, mask = entry.split("/", 2)
-%>
	"<%= subnet %>"/<%= mask %>;
<% end -%>
<% if @realm == "production" -%>
	! "10.68.0.0"/16; # temporary hack, do not treat labs like production
<% end -%>
}

# Backend probes

# frontends in front of other varnish instances should send
# probes that don't depend on the app backend
probe varnish {
	.request =
		"GET /check HTTP/1.1"
		"Host: varnishcheck"
		"User-agent: Varnish backend check"
		"Connection: close";
	.timeout = <%= @vcl_config.fetch('varnish_probe_ms') %>ms;
	.interval = 100ms;
	.window = 5;
	.threshold = 3;
}

<%
# backend_caches and app_directors (two different kinds of backend!)
# refactoring here is a W-I-P
#
# Expected data format:
# @backend_caches = { # always defined
#     'cache_eqiad' => {
#         'dc'       => 'eqiad',
#         'service'  => 'foo',
#         'backends' => [ "backend1", "backend2" ], # required: array
#         'be_opts'  => { # every option is required!
#             'port' = 80,
#             'connect_timeout' = '2s',
#             'first_byte_timeout' = '4s',
#             'between_bytes_timeout' = '3s',
#             'max_connections' = 100, # per-backend!
#         },
#     },
# }
#
#
# @app_def_be_opts = { # exactly these 5 options supported/required
#     'port' = 80,
#     'connect_timeout' = '2s',
#     'first_byte_timeout' = '4s',
#     'between_bytes_timeout' = '3s',
#     'max_connections' = 100, # per-backend!
# }
# @app_directors = { # not always defined (e.g. frontends, for now)
#     'foo' => {
#         'backends' => {
#             # At least one core DC must be defined here
#             # If more than one DC, service is active:active
#             'eqiad' => 'foo.svc.eqiad.wmnet',
#             'codfw' => 'foo.svc.codfw.wmnet',
#         },
#         'be_opts' => { # optional overrides of app_def_be_opts
#             'port' = 80,
#             'connect_timeout' = '2s',
#             'first_byte_timeout' = '4s',
#             'between_bytes_timeout' = '3s',
#             'max_connections' = 100, # per-backend!
#         },
#         'probe'   => { # optional probe
#             'url'     => '/piwik.php',
#             'timeout' => '3s',
#         },
#     },
# }
#
# Note that backend hosts defined by more than one director will take their
# options from the first director to define them!  We could fix this by putting
# the director name into the backend host's "backend" name as well, but so far
# we have no cases where this is necessary! (whereas we do have cases of
# duplicate backend hosts where the options are always identical, for
# vslp-vs-random cache backends)
%>

<% if not @varnish_testing -%>

# Generated list of cache backend hosts for director consumption

<%
becache_seen = {}
@backend_caches.keys.sort.each do |director_name|
	director = @backend_caches[director_name]
	be_opts	= director['be_opts']
	[*director['backends']].each do |backend|
		next if becache_seen.key?(backend)
		becache_seen[backend] = 1
		name = 'be_' + backend.gsub(/[-.]/, '_')
-%>

backend <%= name %> {
	.host = "<%= backend %>";
	.port = "<%= be_opts['port'] %>";
	.connect_timeout = <%= be_opts['connect_timeout'] %>;
	.first_byte_timeout = <%= be_opts['first_byte_timeout'] %>;
	.between_bytes_timeout = <%= be_opts['between_bytes_timeout'] %>;
	.max_connections = <%= be_opts['max_connections'] %>;
	.probe = varnish;
}

<% end # backend loop -%>
<% end # director loop -%>

# Generated list of applayer backend hosts for director consumption

<%
apphost_seen = {}
@app_directors.keys.sort.each do |director_name|
	director = @app_directors[director_name]
	be_opts = @app_def_be_opts.merge(director['be_opts'] || {})
        if director['backends'].key?(@site)
		backend = director['backends'][@site]
		next if apphost_seen.key?(backend)
		apphost_seen[backend] = 1
		name = 'be_' + backend.gsub(/[-.]/, '_')
-%>

backend <%= name %> {
	.host = "<%= backend %>";
	.port = "<%= be_opts['port'] %>";
	.connect_timeout = <%= be_opts['connect_timeout'] %>;
	.first_byte_timeout = <%= be_opts['first_byte_timeout'] %>;
	.between_bytes_timeout = <%= be_opts['between_bytes_timeout'] %>;
	.max_connections = <%= be_opts['max_connections'] %>;
	<%- if director.key?('probe') -%>
	.probe = {
		.url = "<%= director['probe']['url'] %>";
		.timeout = <%= director['probe']['timeout'] %>;
	}
	<%- end -%>
}

<% end # @site if-condition -%>
<% end # app_directors loop -%>

<% end # !varnish_testing -%>

sub wm_common_directors_init {
<% if @dynamic_backend_caches -%>
include "directors.<%= @inst %>.vcl";
<% else -%>
<% @backend_caches.keys.sort.each do |director_name|
director = @backend_caches[director_name]
backends = director['backends'] -%>
	new <%= director_name %> = directors.shard();
	new <%= director_name %>_random = directors.random();
<%
	backends.each do |backend|
		name = 'be_' + backend.gsub(/[-.]/, '_')

		# Override backend name for test VCL files. This way we can use
		# "vtc_backend" as the backend name in our VTC tests.
		if @varnish_testing
			name = "vtc_backend";
		end
-%>
		<%= director_name %>.add_backend(<%= name %>);
		<%= director_name %>_random.add_backend(<%= name %>, 100);
<% 	end #backends loop -%>
	<%= director_name %>.reconfigure();
<% end #director loop -%>

<% end #dynamic_backend_caches -%>

<%
@app_directors.keys.sort.each do |director_name|
        if @app_directors[director_name]['backends'].key?(@site)
		backend = @app_directors[director_name]['backends'][@site]
		if @varnish_testing
			name = "vtc_backend";
		else
			name = 'be_' + backend.gsub(/[-.]/, '_')
		end
-%>
	new <%= director_name %> = directors.random();

		<%= director_name %>.add_backend(<%= name %>, 100);
<% end # @site if-condition -%>
<% end # app_directors loop -%>

} # end wm_common_directors_init

# Functions

sub wm_common_recv_pass {
<%
    def uc_action(uc)
        if uc == "pass"
            return "return (pass);"
        elsif uc == "pipe"
            return "return (pipe);"
        elsif uc == "websockets"
            return %Q[if (req.http.upgrade ~ "(?i)websocket") { return (pipe); } else { return (pass); }]
        elsif uc == "normal"
            return ""
        else
            raise Error, "Invalid caching action #{uc}"
        end
    end

    caching = []
    caching_default = false
    @vcl_config['req_handling'].keys.sort.each do |reqhost|
        if reqhost == 'default'
            host_cmp = %Q[x] # unused below
        elsif reqhost =~ /^[-.A-Za-z0-9]+$/
            host_cmp = %Q[if (req.http.host == "#{reqhost}")]
        else
            host_cmp = %Q[if (req.http.host ~ "#{reqhost}")]
        end

        need_host = false
        host_action = false
        options = @vcl_config['req_handling'][reqhost]
        if options.has_key?('caching')
            host_action = uc_action(options['caching'])
            need_host = true
        end

        if options.has_key?('subpaths')
            path_ifs = []
            options['subpaths'].keys.sort.each do |subpath|
                path_options = options['subpaths'][subpath]
                path_cmp = %Q[if (req.url ~ "#{subpath}")]
                if path_options.has_key?('caching')
                    need_host = true
                    path_action = uc_action(path_options['caching'])
                    path_ifs.push(%Q[#{path_cmp} {\n             #{path_action}\n        }])
                else
                    path_ifs.push(%Q[#{path_cmp} {\n        }])
                end
            end
            if need_host
                if host_action
                    path_ifs.push(%Q[e {\n            #{host_action}\n        }])
                end
                host_action = path_ifs.join(' els')
            end
        end

        if need_host
            if reqhost == 'default'
                caching_default = host_action
            else
                caching.push(%Q[#{host_cmp} {\n        #{host_action}\n    }])
            end
        end
    end

    if caching.empty?
        if caching_default
            caching_vcl = caching_default
        else
            caching_vcl = %Q[]
        end
    else
        if caching_default
            caching.push(%Q[e {\n        #{caching_default}\n    }])
        end
        caching_vcl = caching.join(' els');
    end
%>
    <%= caching_vcl %>
}

sub wm_common_recv_purge {
	/* Support HTTP PURGE */
	if (req.method == "PURGE") {
		if (client.ip !~ local_host) {
			return (synth(405, "Method not allowed"));
		} elsif (req.http.Host ~ "<%= @vcl_config.fetch('purge_host_regex') %>") {
			set req.hash_ignore_busy = true;
			return (purge);
		} else {
			return (synth(204, "Domain not cached here"));
		}
	}
}

sub wm_common_recv_early {
	unset req.http.X-CDIS; // clear internal cache-disposition header

	// To pass this check, the method must be in allowed_methods (even OPTIONS must be there to be supported),
	// Additionally, if OPTIONS is allowed, it must be accompanied by Origin:
	if (req.method !~ "<%= @vcl_config.fetch("allowed_methods", "^(GET|HEAD|POST|OPTIONS|PURGE)$") %>"
		|| (req.method == "OPTIONS" && !req.http.Origin)) {
		return (synth(405, "Method not allowed"));
	}

	if ( req.http.host ~ "^varnishcheck" ) {
		return (synth(200, "healthcheck"));
	}
}

sub wm_common_hit {
	set req.http.X-CDIS = "hit";
}

sub wm_common_miss {
	set req.http.X-CDIS = "miss";
}

sub wm_common_pass {
	set req.http.X-CDIS = "pass";
}

sub wm_common_synth {
	if (resp.reason == "healthcheck") {
		set resp.reason = "OK";
		synthetic("Varnish <%= @inst %> running on <%= @hostname %> is up");
	}
}

sub wm_common_backend_response {
	// This prevents the application layer from setting this in a response.
	// We'll be setting this same variable internally in VCL in hit-for-pass
	// cases later.
	unset beresp.http.X-CDIS;

	// Set a maximum cap on the TTL for 404s. Objects that don't exist now may
	// be created later on, and we want to put a limit on the amount of time it
	// takes for new resources to be visible.
	if (beresp.status == 404 && beresp.ttl > <%= @vcl_config.fetch("ttl_cap_404", "10m") %>) {
		set beresp.ttl = <%= @vcl_config.fetch("ttl_cap_404", "10m") %>;
	}

	// Set keep, which influences the amount of time objects are kept available
	// in cache for IMS requests (TTL+grace+keep). Scale keep to the app-provided
	// TTL.
	if (beresp.ttl > 0s) {
		if (beresp.http.ETag || beresp.http.Last-Modified) {
			if (beresp.ttl < <%= @vcl_config.fetch("keep", "7d") %>) {
				set beresp.keep = beresp.ttl;
			} else {
				set beresp.keep = <%= @vcl_config.fetch("keep", "7d") %>;
			}
		}

		// Hard TTL cap on all fetched objects (default 1d)
		if (beresp.ttl > <%= @vcl_config.fetch("ttl_cap", "1d") %>) {
			set beresp.ttl = <%= @vcl_config.fetch("ttl_cap", "1d") %>;
		}

		set beresp.grace = <%= @vcl_config.fetch("def_grace", "20m") %>;
	}

	// Swizzled random reduction of all TTLs by up to 5%, to avoid various
	// possible cases of stampedes of aligned natural expiries.
	// Note VCL supports DURATION*REAL natively, and DURATIONs do support
	// fractional seconds, so this doesn't technically need a guard
	// condition against short TTLs.
	// However, sub-second TTLs like 0.97s might poke edge cases in VCL,
	// which would be a good reason to not do this for TTLs < 2s.
	// Furthermore, swizzling a stampede of very short TTLs such that they
	// expire milliseconds apart may do more perf harm than good.  60s
	// seems like a reasonably-conservative cutoff, where the swizzle will
	// be spreading things by ~3s.
	if (beresp.ttl >= 60s) {
		set beresp.ttl = beresp.ttl * std.random(0.95, 1.0);
	}

	// Compress compressible things if the backend didn't already, but
	// avoid explicitly-defined CL < 860 bytes.  We've seen varnish do
	// gzipping on CL:0 302 responses, resulting in output that has CE:gzip
	// and CL:20 and sends a pointless gzip header.
	// Very small content may actually inflate from gzipping, and
	// sub-one-packet content isn't saving a lot of latency for the gzip
	// costs (to the server and the client, who must also decompress it).
	// The magic 860 number comes from Akamai, Google recommends anywhere
	// from 150-1000.  See also:
	// https://webmasters.stackexchange.com/questions/31750/what-is-recommended-minimum-object-size-for-gzip-performance-benefits
	if (beresp.http.content-type ~ "json|text|html|script|xml|icon|ms-fontobject|ms-opentype|x-font|sla"
		&& (!beresp.http.Content-Length || std.integer(beresp.http.Content-Length, 0) >= 860)) {
			set beresp.do_gzip = true;
	}

	// Do not cache private, no-cache, no-store, zero-maxage objects. Disable
	// request coalescing of uncacheable responses.
	if (beresp.status < 500 && beresp.http.Cache-Control ~ "(private|no-cache|no-store|max-age=0|s-maxage=0)") {
		set beresp.keep = 0s;

		// How long are we keeping an expired HFP/HFM object for
		// stale-while-revalidate-like purposes. In case of slow applayer
		// responses, request coalescing can end up being
		// accidentally enabled during the period of time between
		// the expiration of HFP/HFM and the applayer responding
		// with a CC header that would cause Varnish to re-create an
		// HFP/HFM object by entering this branch. Set a grace period higher
		// than the slowest possible applayer response to ensure request
		// coalescing is always disabled for uncacheable objects.
		set beresp.grace = 61s; // XXX: is this the slowest possible applayer response?

		set beresp.http.X-CDIS = "pass";

		if (beresp.http.ETag || beresp.http.Last-Modified) {
			// Use HFP for responses with ETag or Last-Modified as they are
			// candidates for conditional requests. See T180712.
			return(pass(90s));
		} else {
			// HFM otherwise.
			set beresp.ttl = 90s;
			set beresp.uncacheable = true;
			return(deliver);
		}
	}
}

// call just before wm_common_xcache_deliver, but only in vcl_deliver, not vcl_synth
sub wm_common_deliver_hitcount {
	if (req.method != "PURGE") {
		if(req.http.X-CDIS == "hit") {
			// obj.hits isn't known in vcl_hit, and not useful for other states
			set req.http.X-CDIS = "hit/" + obj.hits;
		}
	}
}

sub wm_common_xcache_deliver {
	if (req.method != "PURGE") {
		// we copy through from beresp->resp->req here for the initial hit-for-pass case
		if (resp.http.X-CDIS) {
			set req.http.X-CDIS = resp.http.X-CDIS;
			unset resp.http.X-CDIS;
		}

		if (!req.http.X-CDIS) {
			set req.http.X-CDIS = "bug";
		}

		// X-Cache-Int gets appended-to as we traverse cache layers
		if (resp.http.X-Cache-Int) {
			set resp.http.X-Cache-Int = resp.http.X-Cache-Int + ", <%= @hostname %> " + req.http.X-CDIS;
		} else {
			set resp.http.X-Cache-Int = "<%= @hostname %> " + req.http.X-CDIS;
		}
	}
}

sub wm_common_deliver_error_with_empty_body {
    // Provides custom error html if error response has no body
    if (resp.http.Content-Length == "0" && resp.status >= 400) {
        # Varnish doesn't define status codes from RFC6585
        if (resp.status == 428) {
            return(synth(resp.status, "Precondition Required"));
        } elseif (resp.status == 429) {
            return(synth(resp.status, "Too Many Requests"));
        } elseif (resp.status == 431) {
            return(synth(resp.status, "Request Header Fields Too Large"));
        } elseif (resp.status == 511) {
            return(synth(resp.status, "Network Authentication Required"));
        }
        return(synth(resp.status));
    }
}
