vcl 4.0;

// common backend code for all clusters
include "<%= @varnish_include_path %>wikimedia-common_<%= @vcl %>.inc.vcl";

/* Include the VCL file for this role */
include "<%= @varnish_include_path %><%= @vcl %>.inc.vcl";

sub vcl_init {
	call wm_common_directors_init;
}

sub vcl_recv {
	if (client.ip !~ wikimedia_trust) {
		// Do not allow direct access to non-frontend layers
		return (synth(403, "Access denied"));
	}

	call wm_common_recv_early;

	// Backend loop detection: if a mistake is made in the code or config
	// for inter-cache routing, a request could loop infinitely between
	// backend caches without some sort of protection like
	// this.  The header may be re-used later for sideways
	// Only-If-Cached support as well.
	if (req.restarts == 0) {
		if (req.http.X-DCPath) {
			if (req.http.X-DCPath ~ "<%= @site %>") {
				return (synth(508, "Loop Detected"));
			}
			set req.http.X-DCPath = req.http.X-DCPath + ", <%= @site %>";
		} else {
			set req.http.X-DCPath = "<%= @site %>";
		}
	}

<% if @cache_route == 'direct' -%>
	// tier-one caches must select an applayer backend
	call cluster_be_recv_applayer_backend;
<% else -%>
	set req.backend_hint = cache_<%= @cache_route %>.backend();
<% end -%>

	call cluster_be_recv_pre_purge;
	call wm_common_recv_purge;
	call cluster_be_recv;

	return (hash); // no default VCL
}

sub vcl_hash {
	call cluster_be_hash;
	// default vcl_hash invokes here!
}

// http://book.varnish-software.com/4.0/chapters/Cache_Invalidation.html
sub vcl_purge {
	return (synth(204, "Purged"));
}

sub vcl_hit {
	call wm_common_hit;
	call wm_common_hit_grace;
	call cluster_be_hit;
	// no default VCL. Expired ttl/grace behavior implemented in
	// wm_common_hit_grace.
	return (deliver);
}

sub vcl_miss {
	call wm_common_miss;
	call cluster_be_miss;
	return (fetch); // no default VCL (which is just "return (fetch)" anyways)
}

sub vcl_pass {
	call wm_common_pass;

<% if @vcl_config.fetch("pass_random", false) -%>
<% if @cache_route != 'direct' -%>
	// pass-traffic should not use consistent hashing, to avoid unecessary
	// traffic focus on one node and keep things performant, *if* we're
	// fairly sure that all layers/tiers make equivalent pass decisions...
	set req.backend_hint = cache_<%= @cache_route %>_random.backend();
<% end -%>
<% end -%>

	call cluster_be_pass;
	return (fetch); // no default VCL (which is just "return (fetch)" anyways)
}

sub vcl_pipe {
	// for websockets over pipe
	if (req.http.upgrade) {
		set bereq.http.upgrade = req.http.upgrade;
	}
}

sub vcl_backend_fetch {
    call cluster_be_backend_fetch;
}

sub vcl_backend_response {
	call cluster_be_backend_response_early; // e.g. to fix up Vary-slotting in bereq
	call wm_common_backend_response;
	call cluster_be_backend_response;
	// default vcl_(fetch|backend_response) invokes here, unless cluster VCL unconditionally returns!
}

sub vcl_deliver {
	call wm_common_deliver_hitcount;
	call wm_common_xcache_deliver;
	call cluster_be_deliver;
	return (deliver); // no default VCL (which is just "return (deliver)" anyways)
}

// Varnish4 vcl_synth+vcl_backend_error

sub vcl_synth {
	set resp.http.X-CDIS = "int";
	call wm_common_xcache_deliver;
	if (resp.status >= 400) {
		call synth_errorpage;
	}
	return (deliver);
}

sub vcl_backend_error {
	set beresp.http.X-CDIS = "int";
	call backend_error_errorpage;
	return (deliver);
}
