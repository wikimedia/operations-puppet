# NOTE: This file is managed by Puppet.

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"

# Dynamic allocation allows Spark to dynamically scale the cluster resources
# allocated for an application based on the workload. Only available in YARN mode.
# More info: https://spark.apache.org/docs/2.1.2/configuration.html#dynamic-allocation
spark.dynamicAllocation.enabled                     true
spark.shuffle.service.enabled                       true
spark.dynamicAllocation.executorIdleTimeout         60s
spark.dynamicAllocation.cachedExecutorIdleTimeout   3600s
<% if @hive_enabled -%>
spark.sql.catalogImplementation                     hive
<% end -%>
<% if @driver_port -%>
spark.driver.port                                   <%= @driver_port %>
spark.port.maxRetries                               <%= @port_max_retries %>
<% end -%>
<% if @ui_port -%>
spark.ui.port                                       <%= @ui_port %>
<% end -%>
spark.yarn.archive                  hdfs:///user/spark/share/lib/spark2-assembly.zip
<% @extra_settings.sort.each do |key, value| -%>
<%= key %>   <%= value %>
<% end -%>