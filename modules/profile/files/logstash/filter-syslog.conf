# vim:set sw=2 ts=2 sts=2 et
# Parse syslog input
filter {
  if [type] == "syslog" {

    # General syslog message cleanup
    mutate {
      replace => [ "host", "%{logsource}" ]
      add_tag => [ "syslog", "es" ]
    }

    if [program] == "node" {
        mutate {
          replace => [ "level", "%{severity}" ]
          rename => {
            "msg" => "message"
            "name" => "type"
          }
          # Remove syslog and bunyan added fields
          remove_field => [
              "facility", # syslog
              "hostname", # bunyan
              "logsource", # syslog
              "priority", # syslog
              "program", # syslog
              "severity", # syslog
              "time", # bunyan
              "timestamp", # syslog
              "v" # bunyan
          ]
        }
    } else if [program] =~ "/^mjolnir-/" {
        # do not mutate level
    } else {
        mutate {
          # Deprecated. `severity_label` is an artifact of the logstash syslog
          # plugin and should be replaced with `severity` upon migration to kafka
          # logging pipeline.
          add_field => { "level" => "%{severity_label}" }
        }
    } # end if [program] == "node"

    mutate {
      # "\n" newline notation in substitution results in "\\n" in output.
      # Using a string with a literal newline works as desired.
      gsub => [ "message", "#012", '
' ]
    }

    # Strip "message repeated" preamble
    if [message] =~ /^message repeated \d+ times:/ {
      grok {
        match => [
          "message",
          "^message repeated %{NUMBER:repeated} times: \[\s*%{GREEDYDATA:message}\]$"
        ]
        overwrite => [ "message" ]
        named_captures_only => true
      }
    }

    # Mark kernel messages forwarded because of hhvm as hhvm messages
    if [program] == "kernel" and [message] =~ /hhvm/ {
      mutate {
        replace => [ "program",  "hhvm" ]
      }
    }

    if [program] == "hhvm" {
      mutate {
        replace => [ "type",  "hhvm" ]
        # Strip leading newline from hhvm messages
        strip => [ "message" ]
      }

      if [message] =~ /^(?m){.*}$/ {
        # Parse json encoded fatal errors
        json {
          source => "message"
          add_tag => [ "hhvm-json" ]
        }
        mutate {
          replace => [
            "message", "%{message} in %{file} on line %{line}",
            "level", "Fatal"
            ]
        }
      } else {
        grok {
          match => [
            "message",
            "^%{LOGLEVEL:level}"
          ]
          overwrite => [ "level" ]
          named_captures_only => true
        }
      }
    } # end [program] == "hhvm"

    if [program] == "hhvm-fatal" {
      mutate {
        replace => [
          "type",  "hhvm",
          "level", "Fatal"
        ]
      }
    } # end [program] == "hhvm-fatal"

    if [program] == "apache2" {
      mutate {
        replace => [ "type",  "apache2" ]
      }

      # Parse typical apache error format:
      # [channel:level] [pid N:tid N] MSG? [client HOST:PORT] MSG, referer: URL
      grok {
        match => [
          "message",
          "^\[(%{WORD:channel}?:)?%{LOGLEVEL:level}\]\s+(\[pid %{POSINT}(:tid %{POSINT:thread})?\]\s+)?(?<message_prefix>[^\[]+)?(\[client %{IP:clientip}(:%{POSINT:clientport})?\]\s+)?%{DATA:message}(,\s+referer:\s+%{NOTSPACE:referrer})?$"
        ]
        overwrite => [ "message", "level" ]
        named_captures_only => true
      }

      if [message_prefix] {
        mutate {
          "replace" => [ "message", "%{message_prefix}%{message}" ]
          "remove_field" => [ "message_prefix" ]
        }
      }

    } # end [program] == "apache2"

    if [program] == "mediawiki" {
      mutate {
        replace => [ "type",  "mediawiki" ]
      }
      if [message] =~ /^{.*}$/ {
        mutate {
          # Remove syslog added fields
          remove_field => [
              "facility",
              "logsource",
              "priority",
              "program",
              "severity",
              "timestamp"
          ]
        }
        # Parse message as json to unpack logstash record
        json {
          source => "message"
        }
      } else {
        # Mark up the message as JSON that was cut off by the syslog transport
        mutate {
          add_field => { "channel" => "jsonTruncated" }
          add_tag => [ "syslog_truncated" ]
        }
      }
    } # end [program] == "mediawiki"

    if [program] == "wdqs" {
      mutate {
        replace => [ "type",  "wdqs" ]
      }

      # nginx access logs
      if [facility_label] == "local7" {
        # https://github.com/wikimedia/operations-puppet/blob/3218df6/modules/wdqs/templates/nginx.erb#L1-L6
        grok {
          match => [
            "message",
            "^\[%{HTTPDATE:http_date}\] .%{WORD:http_method} %{NOTSPACE:message} HTTP/%{NUMBER:httpversion}. %{NUMBER:status} (?:%{NUMBER:response_size}|-) %{QS:referrer} %{QS:user_agent} %{NUMBER:request_time} %{NUMBER:upstream_time} (?:%{IP:clientip}|-) %{IP:remote_addr}$"
          ]
          overwrite => [ "message" ]
          named_captures_only => true
          add_field => { "channel" => "nginx" }
        }

        if !("_grokparsefailure" in [tags]) {
          mutate {
            add_field => {
              "message_decoded" => "%{message}"
            }
          }

          urldecode {
            field => "message_decoded"
          }
        }

        mutate {
          # Remove syslog added fields
          remove_field => [
              "facility",
              "logsource",
              "priority",
              "program",
              "severity",
              "timestamp"
          ]
        }
      } # end [facility_label] == "local7"
    } # end [program] == "wdqs"
  }
}
