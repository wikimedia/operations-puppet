class dataset::cron::wikitech_dumps(
    $enable = true,
    $user   = root,
    $url    = undef,
) {

    if ($enable) {
        $ensure = 'present'
    }
    else {
        $ensure = 'absent'
    }

    include dataset::dirs

    $wikitechdir = "${dataset::dirs::otherdir}/wikitech"

    file { $wikitechdir:
        ensure => 'directory',
        owner  => 'root',
        group  => 'root',
        mode   => '0755',
    }

    $wget = '/usr/bin/wget'
    # don't get anything with query params
    $wgetreject = "--reject-regex '(.*)\\?(.*)'"
    $wgetargs = "-nv -e robots=off -k -nH --wait 30 -np -m ${url} -P ${wikitechdir}"
    # filter out any whines about missing timestamp for index.html
    # as well url download announcements and summary, we only care about anything else
    $filter = "2>&1  | grep -E -v '(turned off|URL:http|FINISHED|Total|Downloaded)'"
    # toss wikitech's autogenerated index.html files when done
    $cleanuphtml = "find ${wikitechdir} -name 'index.html*' -exec rm {} \\;"
    # remove dumps older than 90 days
    $cleanupold = "find ${wikitechdir} -type f -mtime +90 -exec rm {} \\;"

    cron { 'wikitech-dumps-grab':
        ensure  => $ensure,
        command => "${wget} ${wgetreject} ${wgetargs} ${filter}; ${cleanuphtml}; ${cleanupold}",
        user    => $user,
        minute  => '20',
        hour    => '3',
    }
}
