# These settings are applied to all cloud-vps VMs in the eqiad1 deployment.

cluster: misc
datacenters: [eqiad]
has_nrpe: false

authdns_servers:
  "ns0.openstack.eqiad1.wikimediacloud.org": 185.15.56.162
  "ns1.openstack.eqiad1.wikimediacloud.org": 185.15.56.163

profile::resolving::nameservers:
  - "ns-recursor.openstack.eqiad1.wikimediacloud.org"

ldap:
  ro-server: ldap-ro.eqiad.wikimedia.org
  ro-server-fallback: ldap-ro.codfw.wikimedia.org
  rw-server: ldap-rw.eqiad.wikimedia.org
  rw-server-fallback: ldap-rw.codfw.wikimedia.org
profile::base::overlayfs: true
profile::monitoring::raid_check: false

profile::resolving::domain_search:
  - "%{facts.networking.domain}"
  - "%{::wmcs_project}.eqiad1.wikimedia.cloud"
  - "%{::wmcs_project}.eqiad.wmflabs"
  - "eqiad.wmflabs"

profile::openstack::eqiad1::version: "zed"
profile::openstack::base::region: "eqiad1-r"
profile::openstack::eqiad1::nova_controller: "openstack.eqiad1.wikimediacloud.org"
profile::openstack::eqiad1::keystone_host: "openstack.eqiad1.wikimediacloud.org"
profile::openstack::eqiad1::keystone_api_fqdn: "openstack.eqiad1.wikimediacloud.org"
profile::openstack::base::observer_user: "novaobserver"
profile::openstack::base::observer_project: "observer"
profile::openstack::eqiad1::region: "eqiad1-r"
# publicly available read-only credentials
profile::openstack::eqiad1::observer_password: "Fs6Dq2RtG8KwmM2Z"

profile::openstack::base::puppetmaster::enc_client::api_endpoint: "https://puppet-enc.cloudinfra.wmcloud.org"

profile::prometheus::varnishkafka_exporter::stats_default:
  kafka: # https://github.com/edenhill/librdkafka/blob/master/STATISTICS.md
    "metadata_cache_cnt":
      "type": "GaugeMetricFamily"
      "name": "rdkafka_producer_metadata_cache_cnt"
      "description": "Number of topics in the metadata cache."
      "labels": ["client_id"]

# Other overrides
elasticsearch::version: 2
elasticsearch::minimum_master_nodes: 1
elasticsearch::recover_after_time: "1m"
elasticsearch::heap_memory: "2G"
elasticsearch::expected_nodes: 1
elasticsearch::recover_after_nodes: 1
archiva::proxy::ssl_enabled: false
archiva::proxy::certificate_name: ssl-cert-snakeoil
profile::puppetdb::jvm_opts: "-Xmx4G"
profile::puppetdb::elk_logging: false
profile::puppetdb::ca_path: "/etc/ssl/certs/Puppet_Internal_CA.pem"
profile::puppetdb::puppetboard_hosts: []
profile::puppetdb::ssldir: ~
profile::puppetdb::microservice::enabled: false
profile::puppetdb::microservice::port: 8090
profile::puppetdb::microservice::uwsgi_port: 8091
profile::puppetdb::microservice::allowed_hosts: []
profile::puppetdb::microservice::allowed_roles: []

profile::puppetmaster::common::hiera_config: wmcs-eqiad1

puppetmaster::servers:
  "%{lookup('puppetmaster')}":
    - { worker: "%{lookup('puppetmaster')}", loadfactor: 10 }

# Default to Dummy authenticator in JupyterHubs in labs
jupyterhub::authenticator: dummy

# Cache-layer stuff
profile::cache::base::performance_tweaks: false
profile::cache::purge::kafka_topics:
  - eqiad.resource-purge
profile::cache::varnish::frontend::cache_be_opts:
  port: 3128
  connect_timeout: "3s"
  first_byte_timeout: "65s"
  between_bytes_timeout: "33s"
  max_connections: 5000
  probe: "varnish"
profile::cache::varnish::frontend::backends_in_etcd: false
profile::cache::varnish::frontend::runtime_params:
  - default_ttl=3600
profile::cache::varnish::frontend::fe_vcl_config:
  allowed_methods: "^(GET|HEAD|OPTIONS|PATCH|POST|PURGE|PUT|DELETE)$"
  purge_host_regex: '^(?!(upload|upload\.wikimedia|maps)\.beta\.wmflabs\.org)'
  static_host: "en.wikipedia.beta.wmflabs.org"
  top_domain: "beta.wmflabs.org"
  shortener_domain: "w-beta.wmflabs.org"
  upload_domain: "upload.wikimedia.beta.wmflabs.org"
  upload_webp_hits_threshold: 1000
  maps_domain: "maps.beta.wmflabs.org"
  varnish_probe_ms: 100
  keep: "1d"
  public_clouds_shutdown: false
  large_objects_cutoff: 262144

profile::netconsole::client::ensure: absent
profile::trafficserver::backend::storage_elements:
  - devname: vdb
  - pathname: /var/cache/trafficserver
    size: 256M
profile::trafficserver::backend::outbound_tls_settings:
  cacert_dirpath: /etc/ssl/certs
  cacert_filename: Puppet_Internal_CA.pem
  common:
    cipher_suite: -ALL:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384
    enable_tlsv1: 0
    enable_tlsv1_1: 0
    enable_tlsv1_2: 1
    enable_tlsv1_3: 0
  verify_origin: true
  # ATS 9.1.2 uses verify_server_policy
  verify_server_policy: ENFORCED
profile::trafficserver::backend::log_formats:
  - name: wmf
    format: "Date:%<cqtd> Time:%<cqtt> ConnAttempts:%<sca> ConnReuse:%<sstc> TTFetchHeaders:%<{TS_MILESTONE_SERVER_READ_HEADER_DONE-TS_MILESTONE_SM_START}msdms> OriginServer:%<shn> OriginServerTime:%<stms> CacheResultCode:%<crc> CacheWriteResult:%<cwr> ReqMethod:%<cqhm> RespStatus:%<pssc> OriginStatus:%<sssc> ReqURL:%<cquuc> BereqURL:%<cqtx> ReqHeader:User-Agent:%<{User-agent}cqh> ReqHeader:Host:%<{Host}cqh> ReqHeader:X-Client-IP:%<{X-Client-IP}cqh> ReqHeader:Cookie:%<{Cookie}cqh> RespHeader:X-Cache-Int:%<{X-Cache-Int}psh> RespHeader:Backend-Timing:%<{Backend-Timing}psh>"
profile::trafficserver::backend::log_filters:
  - name: notpurge
    action: reject
    condition: cqhm MATCH PURGE
  - name: notvarnishcheck
    action: reject
    condition: "%<{User-agent}cqh> MATCH Varnish backend check"
profile::trafficserver::backend::logs:
  - filename: notpurge
    format: wmf
    filters:
      - notpurge
      - notvarnishcheck
    mode: ascii_pipe
    ensure: present
profile::trafficserver::backend::default_lua_script: "default"

zookeeper_clusters:
  "%{::wmcs_project}":
    hosts:
      "%{::fqdn}": 1

profile::ssh::server::disable_agent_forwarding: false

puppetmaster: "puppetmaster.cloudinfra.wmflabs.org"
puppet_ca_source: puppet:///modules/profile/puppet/ca.labs.pem

keystone_public_port: "25000"

# By default, nag project admins about puppet breakage
send_puppet_failure_emails: true

# Oident proxy via default gateway
profile::wmcs::services::oidentd::client::proxy: 172.16.0.1

# For any Analytics Cluster in labs:
bigtop::hadoop::datanode_mounts:
  - /var/lib/hadoop/data/a
  - /var/lib/hadoop/data/b

# Default to creating home directories for all
# users in the current Labs Project.
bigtop::hadoop::users::groups: project-%{::wmcs_project}

labsldapconfig:
  hostname: ldap-ro.eqiad.wikimedia.org

profile::openldap::hostname: ldap-rw.eqiad.wikimedia.org

profile::diffscan::instances:
  public-v4-from-labs:
    ranges:
      - 185.15.58.0/23
      - 91.198.174.0/24
      - 198.35.26.0/23
      - 208.80.152.0/22
      - 103.102.166.0/24
      - 185.71.138.0/24 # Wikidough
    email: root@wikimedia.org
  cloud-infrastructure:
    ranges:
      - 185.15.56.128/25  # eqiad infrastructure
      - 172.20.255.0/24   # eqiad private service VIPs
      - 185.15.57.0/24    # codfw
      - 172.20.254.0/24   # codfw private service VIPs
    range_configs:
      - realm: labs
        options:
          sphere: private
          description: cloud-private
    email: cloud-admin-feed@lists.wikimedia.org

# User for Jenkins controllers SSH connections to the agents
jenkins_agent_username: "jenkins-deploy"

profile::mail::default_mail_relay::smarthosts:
  - "mx-out-a.wmcloud.org"
  - "mx-out-b.wmcloud.org"
profile::mail::default_mail_relay::mediawiki_smarthosts: []

profile::systemd::timesyncd::ntp_servers:
  - "ntp-03.cloudinfra.eqiad1.wikimedia.cloud"
  - "ntp-04.cloudinfra.eqiad1.wikimedia.cloud"
ntp_peers:
  eqiad:
    - "ntp-03.cloudinfra.eqiad1.wikimedia.cloud"
    - "ntp-04.cloudinfra.eqiad1.wikimedia.cloud"
  codfw: []
  ulsfo: []
  eqsin: []
  drmrs: []
  esams: []

profile::base::systemd::cpu_accounting: "no"
profile::base::systemd::blockio_accounting: "no"
profile::base::systemd::memory_accounting: "no"
profile::base::systemd::ip_accounting: "no"

# Cumin
profile::openstack::eqiad1::cumin::project_masters: []
profile::openstack::eqiad1::cumin::project_pub_key: undef
profile::openstack::base::keystone::auth_protocol: https
profile::openstack::base::keystone::public_port: 25000
profile::openstack::eqiad1::nova::dhcp_domain: "eqiad1.wikimedia.cloud"
cumin_masters:
  - 172.16.4.160 # cloud-cumin-03.cloudinfra.eqiad1.wikimedia.cloud
  - 172.16.2.249 # cloud-cumin-04.cloudinfra.eqiad1.wikimedia.cloud
  - 172.16.1.220 # bastion-restricted-eqiad1-3.bastion.eqiad1.wikimedia.cloud

profile::puppet::agent::dns_alt_names: []

bastion_hosts:
  - 172.16.3.145 # bastion-eqiad1-03.bastion.eqiad1.wikimedia.cloud
  - 172.16.5.168 # bastion-eqiad1-04.bastion.eqiad1.wikimedia.cloud
  - 172.16.1.220 # bastion-restricted-eqiad1-3.bastion.eqiad1.wikimedia.cloud

cache_hosts:
  - 172.16.5.238 # proxy-03.project-proxy.eqiad1.wikimedia.cloud
  - 172.16.5.200 # proxy-04.project-proxy.eqiad1.wikimedia.cloud

# use aliases to provide for backwards compatibility
# perhaps this doesn't work with our current version of puppet
# profile::puppet::agent::puppetmaster: "%{alias('puppetmaster')}"
profile::idp::key_password: changeit
profile::idp::keystore_password: changeit

monitoring_hosts: []

# We do not have support for LVS systems in Cloud VPS
has_lvs: false
service::catalog: {}

# WMCS clusters are squashed into 'misc'
wikimedia_clusters:
  misc:
    description: "Miscellaneous"
    id: 8
    sites:
      eqiad: []
      codfw: []
  cache_text:
    description: "Text caches"
    id: 20
    sites:
      eqiad: []
      codfw: []
      esams: []
      ulsfo: []
      eqsin: []
      drmrs: []
  cache_upload:
    description: "Upload caches"
    id: 22
    sites:
      eqiad: []
      codfw: []
      esams: []
      ulsfo: []
      eqsin: []
      drmrs: []
  parsoid:
    description: "Parsoid"
    id: 37
    sites:
      eqiad: []
      codfw: []


# Central logging for auth.log
profile::syslog::remote::send_logs: auth-logs
profile::syslog::remote::enable: true
profile::syslog::remote::central_hosts_tls:
  default:
  - syslogaudit1.svc.eqiad1.wikimedia.cloud:6514
  - syslogaudit2.svc.eqiad1.wikimedia.cloud:6514
profile::syslog::remote::mtls_provider: 'disabled'
profile::syslog::remote::tls_server_auth: x509/name
profile::syslog::remote::tls_trusted_ca: /etc/ssl/certs/ca-certificates.crt

# we need the ossl driver; gtls doesn't work with acme certs.
profile::syslog::remote::tls_netstream_driver: ossl
profile::syslog::centralserver::tls_netstream_driver: ossl
