kafka_clusters:
  logging-beta:
    zookeeper_cluster_name: main-deployment-prep
    brokers:
      deployment-kafka-logging01.deployment-prep.eqiad1.wikimedia.cloud:
        id: 1001
        rack: B
    ipv6: false

zookeeper_clusters:
  main-deployment-prep:
    hosts:
      deployment-zookeeper02.eqiad.wmflabs: '2'

prometheus_nodes:
  - logging-alert-01.logging.eqiad1.wikimedia.cloud

profile::benthos::instances: {}

# known public
profile::logstash::collector::input_kafka_ssl_truststore_passwords:
  logging-beta: 'changeit'
profile::logstash::collector::input_kafka_consumer_group_id: 'logging-logstash'
# profile::logstash::collector::output_public_loki_host: 'logging-grafana-01.logging.eqiad1.wikimedia.cloud'

# There is no deployment server in the logging env.
scap::deployment_server: "%{facts.fqdn}"
scap::enable_bootstrapping: false

profile::opensearch::dashboards::httpd_proxy::auth_file: '/etc/logstash/htpasswd'
profile::opensearch::dashboards::httpd_proxy::auth_type: 'local'
profile::opensearch::dashboards::httpd_proxy::auth_realm: 'local'
profile::opensearch::dashboards::httpd_proxy::vhost: 'beta-logs.wmcloud.org'
profile::opensearch::dashboards::httpd_proxy::serveradmin: 'root@logging-logstash-03.logging.eqiad1.wikimedia.cloud'
profile::opensearch::dashboards::phatality::provision_scap: false

profile::opensearch::version: '2.0.0'
profile::opensearch::rack: ''
profile::opensearch::row: ''
profile::opensearch::instances: {}
profile::opensearch::base_data_dir: '/srv/opensearch'
profile::opensearch::dc_settings:
  cluster_name: 'logging-beta'
  short_cluster_name: beta
  cluster_hosts:
    - logging-opensearch-ssd-01.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-ssd-02.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-ssd-03.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-ssd-04.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-ssd-05.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-ssd-06.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-hdd-01.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-hdd-02.logging.eqiad1.wikimedia.cloud
    - logging-logstash-02.logging.eqiad1.wikimedia.cloud
    - logging-logstash-03.logging.eqiad1.wikimedia.cloud
  unicast_hosts:
    - logging-opensearch-ssd-01.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-ssd-02.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-ssd-03.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-ssd-04.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-ssd-05.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-ssd-06.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-hdd-01.logging.eqiad1.wikimedia.cloud
    - logging-opensearch-hdd-02.logging.eqiad1.wikimedia.cloud

# unset the explicit version setting
opensearch::curator::version: 'present'

profile::opensearch::common_settings:
  auto_create_index: true
  awareness_attributes: ''
  minimum_master_nodes: 2
  recover_after_nodes: 2
  recover_after_time: '1m'
  # Dont encourage some sort of accidental feedback loop
  send_logs_to_logstash: false
  http_port: 9200
  transport_tcp_port: 9300
  curator_uses_unicast_hosts: false
  filter_cache_size: '10%'
  holds_data: false
  disable_security_plugin: true

profile::opensearch::logstash::jobs_host: 'logging-logstash-03.logging.eqiad1.wikimedia.cloud'
profile::opensearch::logstash::curator_actions:
  '01':
    description: 'logstash: delete older than 14 days'
    action: delete_indices
    options:
      ignore_empty_list: true
    filters:
      - filtertype: pattern
        kind: prefix
        value: 'logstash-'
      - filtertype: age
        source: name
        direction: older
        timestring: '%Y.%m.%d'
        unit: days
        unit_count: 14

  '02':
    description: 'dlq: delete older than 2 days'
    action: delete_indices
    options:
      ignore_empty_list: true
    filters:
      - filtertype: pattern
        kind: prefix
        value: 'dlq-'
      - filtertype: age
        source: name
        direction: older
        timestring: '%Y.%m.%d'
        unit: days
        unit_count: 2

  '03':
    description: 'ecs-default policy rev 1: delete older than 2 weeks'
    action: delete_indices
    options:
      ignore_empty_list: true
    filters:
      - filtertype: pattern
        kind: regex
        value: '^ecs-(1.7.0-\d\d?-default|default-1)-.*$'
      - filtertype: age
        source: name
        direction: older
        timestring: '%Y.%W'
        unit: weeks
        unit_count: 2

  '04':
    description: 'ecs-test policy rev 1: delete older than 2 weeks'
    action: delete_indices
    options:
      ignore_empty_list: true
    filters:
      - filtertype: pattern
        kind: regex
        value: '^ecs-(1.7.0-\d\d?-test|test-1)-.*$'
      - filtertype: age
        source: name
        direction: older
        timestring: '%Y.%W'
        unit: weeks
        unit_count: 2

  '05':
    description: 'ecs-alerts policy rev 1: delete older than 2 weeks'
    action: delete_indices
    options:
      ignore_empty_list: true
    filters:
      - filtertype: pattern
        kind: regex
        value: '^ecs-(1.7.0-\d\d?-alerts|alerts-1)-.*$'
      - filtertype: age
        source: name
        direction: older
        timestring: '%Y.%W'
        unit: weeks
        unit_count: 2

  '06':
    description: 'w3creportingapi-1.0.0: delete older than 2 weeks'
    action: delete_indices
    options:
      ignore_empty_list: true
    filters:
      - filtertype: pattern
        kind: regex
        value: '^w3creportingapi-.*$'
      - filtertype: age
        source: name
        direction: older
        timestring: '%Y.%W'
        unit: weeks
        unit_count: 2

  '20':
    description: 'all: after 1 days set number of replicas to 0'
    action: replicas
    options:
      count: 0
      ignore_empty_list: true
      timeout_override: 120
    filters:
      - filtertype: pattern
        kind: prefix
        exclude: true  # exclude special indexes
        value: '^\..*'
      - filtertype: age
        source: creation_date
        direction: older
        unit: days
        unit_count: 1

  # For any indices prefixed by "logstash-", and have "index.routing.allocation.require.disktype":"ssd" set,
  # and are older than 7 days, set "index.routing.allocation.require.disktype":"hdd".
  '40':
    description: 'logstash: allocate older shards on hdd nodes'
    action: allocation
    options:
      key: disktype
      value: hdd
      allocation_type: require
      ignore_empty_list: true
    filters:
      - filtertype: pattern
        kind: prefix
        value: 'logstash-'
      - filtertype: allocated
        key: disktype
        value: ssd
        allocation_type: require
        exclude: false
      - filtertype: age
        source: creation_date
        direction: older
        unit: days
        unit_count: 7

  # forceMerge "logstash-" prefixed indices older than 2 days (based on index creation_date) to 1 segments per shard.
  # Delay 120 seconds between each forceMerge operation to allow the cluster to quiesce.
  # This action will ignore indices already forceMerged to the same or fewer number of segments per shard,
  # so the 'forcemerged' filter is unneeded.
  '90':
    description: 'all: forcemerge indexes older than 2 days'
    action: forcemerge
    options:
      max_num_segments: 1
      delay: 120
      continue_if_exception: false
    filters:
      - filtertype: pattern
        kind: regex
        exclude: true  # exclude special indexes
        value: '^\..*'
      - filtertype: age
        source: creation_date
        direction: older
        unit: days
        unit_count: 2

profile::grafana::enable_loki: true
profile::grafana::enable_cas: false
profile::grafana::server_aliases: []
profile::grafana::domain: 'localhost'
profile::grafana::config:
  auth.ldap:
    enabled: false
  auth.proxy:
    enabled: false
profile::grafana::loki::allow_from:
  - 'logging-logstash-02.logging.eqiad1.wikimedia.cloud'
  - 'logging-logstash-03.logging.eqiad1.wikimedia.cloud'
profile::grafana::loki::config:
  auth_enabled: false
  server:
    http_listen_port: 3100
    grpc_listen_port: 9096
    # Increase to 20mb from incredibly low 4mb default value.
    # Hitting this limit manifests as a 502 error on the frontend
    # and a "grpc: received message larger than max (<bytes> vs. 4194304)"
    # from the query scheduler
    grpc_server_max_send_msg_size: 20500000
    grpc_server_max_recv_msg_size: 20500000

  common:
    path_prefix: '/var/lib/loki'
    storage:
      filesystem:
        chunks_directory: '/var/lib/loki/chunks'
        rules_directory: '/var/lib/loki/rules'
    replication_factor: 1
    ring:
      instance_addr: '127.0.0.1'
      kvstore:
        store: 'inmemory'

  table_manager:
    retention_deletes_enabled: true
    retention_period: '3d'

  schema_config:
    configs:
      - from: '2022-01-01'
        store: 'boltdb-shipper'
        object_store: 'filesystem'
        schema: 'v11'
        index:
          prefix: 'index_'
          period: '24h'

  limits_config:
    retention_period: 7d

  compactor:
    delete_request_cancel_period: 10m
    retention_enabled: true
    retention_delete_delay: 2h
