acmechief_host: traffic-acmechief01.traffic.eqiad.wmflabs
apt::use_experimental: true
profile::cache::base::varnish_version: 5
profile::cache::varnish::frontend::backends_in_etcd: false
puppetmaster::enable_geoip: true
certificates::acme_chief:
  non-canonical-redirect-1:
    CN: wikipedia.com.traffic.wmflabs.org
    SNI:
    - wikipedia.com.traffic.wmflabs.org
    - '*.wikipedia.com.traffic.wmflabs.org'
    - '*.en-wp.com.traffic.wmflabs.org'
    - en-wp.com.traffic.wmflabs.org
    - '*.en-wp.org.traffic.wmflabs.org'
    - en-wp.org.traffic.wmflabs.org
    authorized_hosts:
    - traffic-ncredir.traffic.eqiad.wmflabs
    authorized_regexes:
    - ^traffic-ncredir.*\.traffic\.eqiad\.wmflabs$
    challenge: dns-01
    prevalidate: true
    skip_invalid_snis: true
    staging_time: 604800
profile::base::systemd::cpu_accounting: 'yes'
profile::base::systemd::blockio_accounting: 'yes'
profile::base::systemd::memory_accounting: 'yes'
profile::base::systemd::ip_accounting: 'yes'
profile::monitoring::hardware_monitoring: 'absent'
profile::monitoring::contact_group: "%{alias('contactgroups')}"
# the -A -i ... part is a gross hack to workaround Varnish partitions
# that are purposefully at 99%. Better ideas are welcome.
profile::monitoring::nrpe_check_disk_options: '-w 6% -c 3% -W 6% -K 3% -l -e -A -i "/srv/sd[a-b][1-3]" -i "/srv/nvme[0-9]n[0-9]p[0-9]" --exclude-type=fuse.fuse_dfs --exclude-type=tracefs'
profile::monitoring::nrpe_check_disk_critical: false
profile::monitoring::raid_check_interval: 10
profile::monitoring::raid_retry_interval: 10
profile::monitoring::notifications_enabled: false
profile::monitoring::is_critical: false
profile::monitoring::monitor_screens: false
profile::monitoring::monitoring_hosts: "%{alias('monitoring_hosts')}"
profile::monitoring::raid_check: false
profile::monitoring::do_paging: "%{alias('do_paging')}"
profile::monitoring::cluster: "%{alias('cluster')}"
profile::monitoring::nagios_group: "%{alias('nagios_group')}"
profile::monitoring::raid_write_cache_policy: ~
profile::monitoring::hosts:
  "%{facts.hostname}":
    critical: "%{alias('profile::monitoring::is_critical')}"
profile::monitoring::services:
  ssh:
    description: 'SSH'
    check_command: 'check_ssh'
    notes_url: 'https://wikitech.wikimedia.org/wiki/SSH/monitoring'
profile::trafficserver::backend::log_formats:
  - name: wmf
    # TTFetchHeaders is the amount of time between the first origin server
    # connection attempt (or shared session attached in case of connection
    # reuse) and when the first byte is received from the origin.
    # ClientTTFB is the time spent between the very beginning of this session
    # and when the response header write to the client starts.
    format: 'Date:%<cqtd> Time:%<cqtt> ConnAttempts:%<sca> ConnReuse:%<sstc> TTFetchHeaders:%<{TS_MILESTONE_SERVER_FIRST_READ-TS_MILESTONE_SERVER_FIRST_CONNECT}msdms> ClientTTFB:%<{TS_MILESTONE_UA_BEGIN_WRITE-TS_MILESTONE_SM_START}msdms> CacheReadTime:%<{TS_MILESTONE_CACHE_OPEN_READ_END-TS_MILESTONE_CACHE_OPEN_READ_BEGIN}msdms> CacheWriteTime:%<{TS_MILESTONE_CACHE_OPEN_WRITE_END-TS_MILESTONE_CACHE_OPEN_WRITE_BEGIN}msdms> TotalSMTime:%<{TS_MILESTONE_SM_FINISH-TS_MILESTONE_SM_START}msdms> OriginServer:%<shn> OriginServerTime:%<stms> CacheResultCode:%<crc> CacheWriteResult:%<cwr> ReqMethod:%<cqhm> RespStatus:%<pssc> OriginStatus:%<sssc> ReqURL:%<cquuc> ReqHeader:User-Agent:%<{User-agent}cqh> ReqHeader:Host:%<{Host}cqh> ReqHeader:X-Client-IP:%<{X-Client-IP}cqh> ReqHeader:Cookie:%<{Cookie}cqh> BerespHeader:Set-Cookie:%<{Set-Cookie}ssh[0:16]> BerespHeader:Cache-Control:%<{Cache-Control}ssh> BerespHeader:Connection:%<{Connection}ssh> RespHeader:X-Cache-Int:%<{X-Cache-Int}psh> RespHeader:Backend-Timing:%<{Backend-Timing}psh>'
profile::trafficserver::backend::log_filters:
  - name: notpurge
    action: reject
    condition: cqhm MATCH PURGE
  - name: notvarnishcheck
    action: reject
    condition: '%<{User-agent}cqh> MATCH Varnish backend check'
profile::trafficserver::backend::logs:
  - filename: notpurge
    format: wmf
    filters:
    - notpurge
    - notvarnishcheck
    mode: ascii_pipe
    ensure: present
abuse_networks:
  blocked_nets:
    comment: 'All traffic will be dropped, with a 403 asking them to email noc@wm.o'
    context:
      - ferm
      - varnish
    networks:
      - '93.184.216.34/32'
  bot_blocked_nets:
    comment: |-
      "Traffic from common bot-like User-Agents (e.g. 'python-requests/')
      will be dropped, with a 403 asking them to email noc@wm.o and to read
      the User-Agent Policy on metawiki.  Browser-like UAs will be allowed.
      (Note that, as of 2019-10-10, the only disallowed UA is 'python-requests/')"
    context:
      - varnish
    networks:
      - '93.184.216.34/32'
  bot_posts_blocked_nets:
    comment: |-
      "POST traffic from bot-like User-Agents (e.g. 'PostmanRuntime/')
      will be dropped, with a 403 asking them to email noc@wm.o and to read
      the User-Agent policy on metawiki.  Browser-like UAs will be allowed."
    context:
      - varnish
    networks:
      - '93.184.216.34/32'
  phabricator_abusers:
    comment: |-
      'This is a list of users who have been known to abuse phabricator'
    context:
      - phabricator
      - varnish
    networks:
      - '93.184.216.34/32'
  public_cloud_nets:
    comment: |-
      "A couple of ec2 networks"
    context:
      - varnish
    networks:
      - 3.5.208.0/22
      - 3.136.0.0/13
  text_abuse_nets:
    comment: 'Abuse block list specific to text-frontend'
    context:
      - varnish
    networks:
      - '93.184.216.34/32'
profile::trafficserver::backend::monitor_enable: false
profile::cache::haproxy::monitoring_enabled: false
profile::cache::varnish::frontend::enable_monitoring: false
