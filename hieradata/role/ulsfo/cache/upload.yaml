# Enable extended haproxy log-format
profile::cache::haproxy::extended_logging: true
profile::cache::haproxy::log_length: 16384
# Benthos
# Use this boolean to gradually rollout benthos on cp hosts with configuration
# for HAProxy log parser
profile::cache::base::use_benthos: true
profile::cache::base::benthos_socket_address: "tcp@127.0.0.1:1221"
profile::benthos::use_geoip: false
profile::benthos::instances:
  haproxy_cache:
    # Prometheus exporter port
    port: 4153
    # List of envvars that will be copied by benthos::instance in
    # separate file (template) and used by main configuration file
    env_variables:
      socket_proto: "tcp"
      socket_address: "127.0.0.1:1221"
      webrequest_topic: "webrequest_upload_test"
      enable_debug: false
      root_cas_file: /etc/ssl/certs/wmf-ca-certificates.crt
      pipeline_threads: -1
      benthos_fqdn: '%{facts.fqdn}'
      benthos_source: "%{lookup('cache::cluster')}"
      buffer_memory_limit_bytes: 524288000
    # These will be used as envvars for kafka input
    kafka:
      cluster: jumbo
      site: eqiad
      topics:
        - "none"

profile::cache::haproxy::sticktables:
  - name: limit-by-path
    type: integer
    size: 1m
    expire: 60s
    store:
      - bytes_out_rate(1s)

profile::cache::haproxy::filters:
  - direction: out
    name: limit-by-path
    size: 300m
    key: path,sdbm(1)
    table: limit-by-path

profile::cache::haproxy::post_acl_actions:
  tls:
    - context: http-request
      verb: set-bandwidth-limit limit-by-path

lookup_options:
  profile::cache::haproxy::sticktables:
    merge:
      strategy: deep
  profile::cache::haproxy::post_acl_actions:
    merge:
      strategy: deep
