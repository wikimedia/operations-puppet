nagios_group: analytics_eqiad
cluster: analytics

# FIXME:
# indirect hiera lookup due to includes in the role:
# role::analytics::hadoop::client
hadoop_zookeeper_cluster_name: main-eqiad
admin::groups:
  - analytics-users
  - analytics-privatedata-users
  - analytics-admins
  # elasticsearch::analytics creates the analytics-search user and group
  # that analytics-search-users are allowed to sudo to.  This is used
  # for deploying files to HDFS.
  - analytics-search-users

profile::hadoop::standby_master::monitoring_enabled: true
profile::hadoop::logstash::enabled: false

# This is the heap zize of YARN daemons ResourceManager and NodeManagers.
# This setting is used to configure the max heap size for both.
# The default is 1000m, we increase it to 2048m in production.
profile::hadoop::common::yarn_heapsize: 2048

# Used to set up jvm heap size usage thresholds
profile::hadoop::standby::namenode_heapsize: 6144

# Prometheus JMX Exporter config templates.
profile::hadoop::common::hadoop_namenode_opts: "-Xms6144m -Xmx6144m -javaagent:/usr/share/java/prometheus/jmx_prometheus_javaagent.jar=%{::ipaddress}:10080:/etc/hadoop/prometheus_hdfs_namenode_jmx_exporter.yaml"
profile::hadoop::common::yarn_resourcemanager_opts: "-Xms2048m -javaagent:/usr/share/java/prometheus/jmx_prometheus_javaagent.jar=%{::ipaddress}:10083:/etc/hadoop/prometheus_yarn_resourcemanager_jmx_exporter.yaml"

profile::analytics::database::meta::backup_dest::hive::metastore_host: 'analytics1003.eqiad.wmnet'
profile::analytics::database::meta::backup_dest::oozie_host: 'analytics1003.eqiad.wmnet'