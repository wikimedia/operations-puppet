# Notify the Data Platform SRE team about services on these hosts
contactgroups: 'admins,team-data-platform'

nagios_group: analytics_eqiad
cluster: analytics

profile::admin::groups:
  - analytics-admins
profile::admin::groups_no_ssh:
  - analytics-privatedata-users
  # elasticsearch::analytics creates the analytics-search user and group
  # that analytics-search-users are allowed to sudo to.  This is used
  # for deploying files to HDFS.
  - analytics-search-users
  - gpu-users


# enable a hardened Java security profile.
# This is needed here because we deploy TLS keys by setting ensure_ssl_config: true.
profile::java::hardened_tls: true

profile::hadoop::common::hadoop_cluster_name: 'analytics-hadoop'

profile::hive::client::hive_service_name: 'analytics-hive'

# This is the setting for the default 12-disks hadoop worker
# More specific settings for other workers are in regex.yaml
profile::hadoop::common::min_datanode_mounts: 10

profile::hadoop::worker::monitoring_enabled: true

# Analytics worker disks are large.  We will install a custom
# NRPE check for them, so the base module's should ignore them.
profile::monitoring::nrpe_check_disk_options: '-w 6% -c 3% -W 6% -K 3% -l -e -A -i "/var/lib/hadoop/data" --exclude-type=tracefs'
profile::monitoring::raid_write_cache_policy: 'WriteBack'

profile::hadoop::worker::ferm_srange: '(($ANALYTICS_NETWORKS $DRUID_PUBLIC_HOSTS $LABSTORE_HOSTS $DSE_KUBEPODS_NETWORKS))'

# Deploy TLS keys and xml configuration files
profile::hadoop::common::ensure_ssl_config: true

prometheus::node_exporter::collectors_extra:
  - meminfo_numa

profile::kerberos::keytabs::keytabs_metadata:
  - role: 'hadoop'
    owner: 'hdfs'
    group: 'hdfs'
    filename: 'hdfs.keytab'
    parent_dir_grp: 'hadoop'
  - role: 'hadoop'
    owner: 'yarn'
    group: 'yarn'
    filename: 'yarn.keytab'
    parent_dir_grp: 'hadoop'
  - role: 'hadoop'
    owner: 'hdfs'
    group: 'hdfs'
    filename: 'HTTP.keytab'
    parent_dir_grp: 'hadoop'

# Context https://phabricator.wikimedia.org/T278353#6976509
profile::kerberos::client::dns_canonicalize_hostname: false

profile::java::java_packages:
  - version: '8'
    variant: 'jdk'
profile::java::extra_args:
  JAVA_TOOL_OPTIONS: "-Dfile.encoding=UTF-8"
profile::contacts::role_contacts: ['Data Platform']

profile::base::certificates::include_bundle_jks: true

# Use the spark3 shuffler for YARN - See T332765
profile::hadoop::spark2::install_yarn_shuffle_jar: false
profile::hadoop::spark3::install_yarn_shuffle_jar: false

# We need to prevent the removal of the python2 packages because of hive and hive-hcatalog
profile::base::remove_python2_on_bullseye: false

profile::puppet::agent::force_puppet7: true
