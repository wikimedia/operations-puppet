# General configs
cluster: logstash
admin::groups:
  - logstash-roots
  - elasticsearch-roots

# ES-specific
# NOTE: cluster_name must be kept in sync with the backend
# node config in hieradata/role/common/collector.yaml
profile::elasticsearch::rack: ''
profile::elasticsearch::row: ''
profile::elasticsearch::instances: {}
profile::elasticsearch::dc_settings: {}
profile::elasticsearch::base_data_dir: '/srv/elasticsearch'
profile::elasticsearch::version: '5.6'
profile::elasticsearch::common_settings:
    auto_create_index: true
    cluster_name: production-logstash-eqiad
    awareness_attributes: ''
    expected_nodes: 6
    heap_memory: '30G'
    minimum_master_nodes: 2
    recover_after_nodes: 2
    recover_after_time: '1m'
    unicast_hosts:
      - logstash1010.eqiad.wmnet
      - logstash1011.eqiad.wmnet
      - logstash1012.eqiad.wmnet
    cluster_hosts:
      - logstash1007.eqiad.wmnet
      - logstash1008.eqiad.wmnet
      - logstash1009.eqiad.wmnet
      - logstash1010.eqiad.wmnet
      - logstash1011.eqiad.wmnet
      - logstash1012.eqiad.wmnet
    http_port: 9200
    transport_tcp_port: 9300
    # Dont encourage some sort of accidental feedback loop
    send_logs_to_logstash: false
    http_port: 9200
    transport_tcp_port: 9300
    curator_uses_unicast_hosts: false
    filter_cache_size: '10%'

profile::kafka::broker::kafka_cluster_name: logging

# Enable SSL/TLS for Kafka.  This requires
# that keystore and truststore files, and
# profile::kafka::broker::ssl_password, are committed in
# the expected location in ops/puppet/private.
profile::kafka::broker::ssl_enabled: true

# Enable basic ACL handling via Zookeeper stored rules
# More info https://phabricator.wikimedia.org/T167304#3478277
profile::kafka::broker::auth_acls_enabled: true

# Enable Monitoring (via Prometheus) and icinga alerts
profile::kafka::broker::monitoring_enabled: true
profile::kafka::broker::monitoring::replica_maxlag_warning: 100000
profile::kafka::broker::monitoring::replica_maxlag_critical: 500000

# (4 disks in the broker HW RAID array)
# Bump this up to get a little more parallelism between replicas.
profile::kafka::broker::num_replica_fetchers: 4
profile::kafka::broker::num_recovery_threads_per_data_dir: 4
profile::kafka::broker::num_io_threads: 4


# To be changed during Kafka broker version upgrades
profile::kafka::broker::inter_broker_protocol_version: 1.1.0

profile::kafka::broker::group_initial_rebalance_delay: 10000

profile::kafka::broker::max_heap_size: '2g'
profile::kafka::broker::num_partitions: 3

diamond::remove: true

profile::elasticsearch::monitor::shard_size_warning: 150
profile::elasticsearch::monitor::shard_size_critical: 200

# the logstash cluster has 3 data nodes, and each shard has 3 replica (each
# shard is present on each node). If one node is lost, 1/3 of the shards
# will be unassigned, with no way to reallocate them on another node, which
# is fine and should not raise an alert. So threshold needs to be > 1/3.
profile::elasticsearch::monitor::threshold: '>=0.34'
