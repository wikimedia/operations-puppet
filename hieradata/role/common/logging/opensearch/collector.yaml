profile::contacts::role_contacts:
  - 'Observability'
profile::base::production::role_description: 'Logstash, OpenSearch non-data node, and OpenSearch Dashboards host'
cluster: logstash

profile::lvs::realserver::pools:
  kibana7:
    services:
      - kibana
      - apache2
  logs-api:
    services:
      - apache2

role::logstash::apifeatureusage::elastic_hosts:
  - search.svc.codfw.wmnet
  - search.svc.eqiad.wmnet

profile::admin::groups:
  - logstash-roots
  - elasticsearch-roots

# OpenSearch Dashboards
profile::opensearch::dashboards::httpd_proxy::vhost: logstash.wikimedia.org
profile::opensearch::dashboards::httpd_proxy::aliases:
  - kibana7.svc.eqiad.wmnet
  - kibana7.svc.codfw.wmnet
profile::opensearch::dashboards::httpd_proxy::serveradmin: noc@wikimedia.org
profile::opensearch::dashboards::httpd_proxy::auth_type: sso

# OpenSearch
# NOTE: short_cluster_name must be kept in sync with the data role (logging/opensearch/data.yaml)
profile::opensearch::version: '2.0.0'
profile::opensearch::rack: ''
profile::opensearch::row: ''
profile::opensearch::instances: {}
profile::opensearch::dc_settings: {}
profile::opensearch::base_data_dir: '/srv/opensearch'
profile::opensearch::common_settings:
  awareness_attributes: ''
  auto_create_index: true
  short_cluster_name: elk7
  expected_nodes: 10
  heap_memory: '4G'
  # The OpenSearch nodes that are run on the same box as Logstash+OpenSearch Dashboards are only used
  # as client nodes to communicate with the backing cluster.
  holds_data: false
  minimum_master_nodes: 2
  recover_after_nodes: 2
  recover_after_time: '1m'

  send_logs_to_logstash: false
  curator_uses_unicast_hosts: false
  http_port: 9200
  transport_tcp_port: 9300
  disable_security_plugin: true

# API access
profile::opensearch::api::httpd_proxy::vhost: logs-api.discovery.wmnet
profile::opensearch::api::httpd_proxy::serveradmin: noc@wikimedia.org
profile::opensearch::api::httpd_proxy::auth_type: local
profile::opensearch::api::httpd_proxy::auth_realm: local
profile::opensearch::api::httpd_proxy::auth_file: '/etc/opensearch-api-htpasswd'
# The basic auth accounts, an hash of username -> hashed-password. Will
# be read from private.git
# To generate a new entry use 'htpasswd' from 'apache2-utils':
#   htpasswd -n foo
#profile::opensearch::api::httpd_proxy::accounts:
#  'foo': '$apr1$HGuvNA0g$L4j7ot6JjhfwPPv8V5uPG1'

# Logstash
logstash::heap_memory: 4g
logstash::java_package: openjdk-11-jdk
logstash::logstash_version: 7
logstash::logstash_package: logstash-oss

profile::prometheus::statsd_exporter::relay_address: ''  # unset to disable relaying

profile::opensearch::monitoring::enable_shard_size_check: false
profile::opensearch::monitoring::enable_unassigned_shard_check: false

# the logstash cluster has 3 data nodes, and each shard has 3 replica (each
# shard is present on each node). If one node is lost, 1/3 of the shards
# will be unassigned, with no way to reallocate them on another node, which
# is fine and should not raise an alert. So threshold needs to be > 1/3.
profile::opensearch::monitoring::threshold: '>=0.34'

profile::tlsproxy::envoy::ssl_provider: 'cfssl'
profile::tlsproxy::envoy::global_cert_name: 'logstash.wikimedia.org'
profile::tlsproxy::envoy::cfssl_options:
  hosts:
    - 'kibana7.svc.codfw.wmnet'
    - 'kibana7.svc.eqiad.wmnet'
    - 'logstash.discovery.wmnet'
    - 'logs-api.discovery.wmnet'
    - 'logs-api.svc.codfw.wmnet'
    - 'logs-api.svc.eqiad.wmnet'
    - 'logstash-next.wikimedia.org'
profile::tlsproxy::envoy::sni_support: 'yes'
profile::tlsproxy::envoy::listen_ipv6: true

mtail::logs:
  - /var/log/logstash/logstash-json.log

profile::base::certificates::include_bundle_jks: true

profile::puppet::agent::force_puppet7: true

# T355836
profile::benthos::instances:
  mw_accesslog_sampler:
    port: 4155
    kafka:
      cluster: logging
      site: "%{::site}"
      topics:
        - "mediawiki.httpd.accesslog"
