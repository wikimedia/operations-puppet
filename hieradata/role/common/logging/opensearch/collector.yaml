profile::contacts::role_contacts:
  - 'Observability'
cluster: logstash

profile::lvs::realserver::pools:
  kibana7:
    services:
      - kibana
      - apache2

role::logstash::apifeatureusage::elastic_hosts:
  - search.svc.codfw.wmnet
  - search.svc.eqiad.wmnet

profile::admin::groups:
  - logstash-roots
  - elasticsearch-roots

# OpenSearch Dashboards
profile::opensearch::dashboards::httpd_proxy::vhost: logstash.wikimedia.org
profile::opensearch::dashboards::httpd_proxy::serveradmin: noc@wikimedia.org
profile::opensearch::dashboards::httpd_proxy::auth_type: ldap
profile::opensearch::dashboards::httpd_proxy::auth_realm: Developer account (use wiki login name not shell) - nda/ops/wmf
# TODO: Convert to read the servers from ldap::ro-server and ldap::ro-server-fallback once Kibana converted to a profile
profile::opensearch::dashboards::httpd_proxy::ldap_authurl: ldaps://ldap-ro.eqiad.wikimedia.org ldap-ro.codfw.wikimedia.org/ou=people,dc=wikimedia,dc=org?cn
profile::opensearch::dashboards::httpd_proxy::ldap_binddn: cn=proxyagent,ou=profile,dc=wikimedia,dc=org
profile::opensearch::dashboards::httpd_proxy::ldap_groups:
  - cn=ops,ou=groups,dc=wikimedia,dc=org
  - cn=nda,ou=groups,dc=wikimedia,dc=org
  - cn=wmf,ou=groups,dc=wikimedia,dc=org

# OpenSearch
# NOTE: short_cluster_name must be kept in sync with the data role (logging/opensearch/data.yaml)
profile::opensearch::version: '2.0.0'
profile::opensearch::rack: ''
profile::opensearch::row: ''
profile::opensearch::instances: {}
profile::opensearch::dc_settings: {}
profile::opensearch::base_data_dir: '/srv/opensearch'
profile::opensearch::common_settings:
  awareness_attributes: ''
  auto_create_index: true
  short_cluster_name: elk7
  expected_nodes: 10
  heap_memory: '4G'
  # The OpenSearch nodes that are run on the same box as Logstash+OpenSearch Dashboards are only used
  # as client nodes to communicate with the backing cluster.
  holds_data: false
  minimum_master_nodes: 2
  recover_after_nodes: 2
  recover_after_time: '1m'

  send_logs_to_logstash: false
  curator_uses_unicast_hosts: false
  http_port: 9200
  transport_tcp_port: 9300

# Logstash
logstash::heap_memory: 1g
logstash::java_package: openjdk-11-jdk
logstash::logstash_version: 7
logstash::logstash_package: logstash-oss

profile::prometheus::statsd_exporter::relay_address: ''  # unset to disable relaying

# these checks should not be here - T218691
profile::opensearch::monitoring::shard_size_warning: 150
profile::opensearch::monitoring::shard_size_critical: 350

# the logstash cluster has 3 data nodes, and each shard has 3 replica (each
# shard is present on each node). If one node is lost, 1/3 of the shards
# will be unassigned, with no way to reallocate them on another node, which
# is fine and should not raise an alert. So threshold needs to be > 1/3.
profile::opensearch::monitoring::threshold: '>=0.34'

# reusing kibana.discovery.wmnet to squelch PCC missing secret() errors
profile::tlsproxy::envoy::global_cert_name: "kibana.discovery.wmnet"

mtail::logs:
  - /var/log/logstash/logstash-json.log

profile::base::certificates::include_bundle_jks: true
