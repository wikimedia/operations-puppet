#
# mediawiki
#
mediawiki_memcached_servers:
  - '10.64.0.180:11211:1'
  - '10.64.0.181:11211:1'
  - '10.64.0.182:11211:1'
  - '10.64.0.183:11211:1 "shard04"'
  - '10.64.0.184:11211:1 "shard05"'
  - '10.64.0.185:11211:1 "shard06"'
  - '10.64.32.161:11211:1 "shard07"'
  - '10.64.32.162:11211:1 "shard08"'
  - '10.64.32.163:11211:1 "shard09"'
  - '10.64.32.164:11211:1 "shard10"'
  - '10.64.32.165:11211:1 "shard11"'
  - '10.64.32.166:11211:1 "shard12"'
  - '10.64.48.101:11211:1 "shard13"'
  - '10.64.48.102:11211:1 "shard14"'
  - '10.64.48.103:11211:1 "shard15"'
  - '10.64.48.104:11211:1 "shard16"'
  - '10.64.48.95:11211:1 "shard17"'
  - '10.64.48.96:11211:1 "shard18"'

# Hosts temporary removed from the pool for maintenance

#
# Ganglia
#
ganglia_aggregators: carbon.wikimedia.org:9649

# Eventlogging
eventlogging_host: 10.64.32.167 # eventlog1001

# Kafka Topic eventlogging-client-side with
# raw eventlogging events has 12 partitions
# in production.  Run 12 processors.
eventlogging_client_side_processors:
    - client-side-00
    - client-side-01
    - client-side-02
    - client-side-03
    - client-side-04
    - client-side-05
    - client-side-06
    - client-side-07
    - client-side-08
    - client-side-09
    - client-side-10
    - client-side-11

# Kafka Topic eventlogging-valid-mixed with
# most eventlogging events has 12 partitions
# in production.  Run 4 mysql consumers
# to insert this data into the log database.
eventlogging_mysql_consumers:
    - mysql-m4-master-00
    # Dropping these consumers because custom replication of
    # eventlogging tables does not work with parallel consumers due to
    # race conditions. We'll bring these back after adding autoincrement ids
    # to eventlogging tables, and having replication script check the ids
    # instead of the time based faulty checking for new events that's happening now.
    # - mysql-m4-master-01
    # - mysql-m4-master-02
    # - mysql-m4-master-03


labs_certmanager_hostname: "labservices1001.wikimedia.org"

# This can be used by clients that need to connect to etcd.
# Unfortunetly it is hardcoded here.
etcd_hosts:
    - conf1001.eqiad.wmnet
    - conf1002.eqiad.wmnet
    - conf1003.eqiad.wmnet

#
# Labs
#

labs_nova_controller: &labsnovacontroller "labcontrol1001.wikimedia.org"
# _spare is a duplicate/backup controller.  In theory it has the
#  same state as the main controller
labs_nova_controller_spare: &labsnovacontrollerspare "labcontrol1002.wikimedia.org"

labs_glance_controller: &labsglancecontroller "labcontrol1001.wikimedia.org"
labs_puppet_master: &labspuppetmaster "labs-puppetmaster-eqiad.wikimedia.org"
labs_keystone_host: &labskeystonehost "labcontrol1001.wikimedia.org"

# These are the old, soon-to-be-phased-out dns servers:
labs_ldap_dns_host: &labsldapdnshost "labs-ns0.wikimedia.org"
labs_ldap_dns_host_secondary: &labsldapdnshostsecondary "labs-ns1.wikimedia.org"

# These are the up-and-coming, better dns servers:
labs_dns_host: &labsdnshost "labs-ns2.wikimedia.org"
labs_recursor: &labsrecursor "labs-recursor1.wikimedia.org"

novaconfig:
  db_host: 'm5-master.eqiad.wmnet'
  glance_host: *labsnovacontroller
  rabbit_host: *labsnovacontroller
  cc_host: *labsnovacontroller
  site_address: '208.80.155.255'
  controller_hostname: *labsnovacontroller
  ldap_host: *labsnovacontroller
  puppet_host: *labsnovacontroller
  puppet_db_host: *labsnovacontroller
  dhcp_domain: 'eqiad.wmflabs'
  live_migration_uri: 'qemu://%s.eqiad.wmnet/system?pkipath=/var/lib/nova'
  zone: eqiad
  scheduler_pool:
    - labvirt1001
    - labvirt1002
    - labvirt1003
    - labvirt1004
    - labvirt1005
    - labvirt1006
    - labvirt1007
    - labvirt1008
    - labvirt1009
    - labvirt1010

keystoneconfig:
  auth_port: '35357'
  auth_protocol: 'http'
  auth_host: 208.80.154.92
  admin_project_id: 'testlabs'
  admin_project_name: 'testlabs'

designateconfig:
  db_host:  'm5-master.eqiad.wmnet'
  db_name: 'designate'
  pool_manager_db_name: 'designate_pool_manager'
  pdns_db_host: 'm5-master.eqiad.wmnet'
  dhcp_domain: 'eqiad'
  pdns_db_name: 'pdns'
  rabbit_host:  *labsnovacontroller
  controller_hostname: *labsnovacontroller
  domain_id_internal_forward: '114f1333-c2c1-44d3-beb4-ebed1a91742b'
  domain_id_internal_reverse: '8d114f3c-815b-466c-bdd4-9b91f704ea60'

labs_baremetal_servers:
  - '10.64.20.12'

# Used in role::analytics::hive::config
hive_server_host: analytics1027.eqiad.wmnet
hive_metastore_host: analytics1027.eqiad.wmnet

# Used in role::analytics::oozie::config
oozie_host: analytics1027.eqiad.wmnet

ldap_labs_hostname: ldap-labs.eqiad.wikimedia.org

#
# Analytics Cluster Configuration:
#
cdh::hadoop::cluster_name: analytics-hadoop

cdh::hadoop::namenode_hosts:
    - analytics1001.eqiad.wmnet
    - analytics1002.eqiad.wmnet

cdh::hadoop::journalnode_hosts:
    - analytics1052.eqiad.wmnet  # Row A3
    - analytics1028.eqiad.wmnet  # Row C2
    - analytics1035.eqiad.wmnet  # Row D2

# analytics* Dell R720s have mounts on disks sdb - sdm.
# (sda is hardware raid on the 2 2.5 drives in the flex bays.)
cdh::hadoop::datanode_mounts:
    - /var/lib/hadoop/data/b
    - /var/lib/hadoop/data/c
    - /var/lib/hadoop/data/d
    - /var/lib/hadoop/data/e
    - /var/lib/hadoop/data/f
    - /var/lib/hadoop/data/g
    - /var/lib/hadoop/data/h
    - /var/lib/hadoop/data/i
    - /var/lib/hadoop/data/j
    - /var/lib/hadoop/data/k
    - /var/lib/hadoop/data/l
    - /var/lib/hadoop/data/m

cdh::hadoop::net_topology_script_template: 'role/analytics_cluster/hadoop/net-topology.py.erb'

# Increase NameNode heapsize independent from other daemons
cdh::hadoop::namenode_opts: "-Xmx4096m"

# Ensure that users in these groups have home directories in HDFS.
cdh::hadoop::hadoop_users_posix_groups: "analytics-users analytics-privatedata-users analytics-admins analytics-search-users"

cdh::hadoop::mapreduce_reduce_shuffle_parallelcopies: 10
cdh::hadoop::mapreduce_task_io_sort_mb: 200
cdh::hadoop::mapreduce_task_io_sort_factor: 10

# NOTE: Hadoop Memory Settings are configured in the
# role::analytics_cluster::hadoop::client class.
# Many of these settings are configured programatically.

cdh::hive::metastore_host: analytics1027.eqiad.wmnet
cdh::oozie::oozie_host: analytics1027.eqiad.wmnet

# Don't auto create Hue users from LDAP in production.
cdh::hue::ldap_create_users_on_login: false
