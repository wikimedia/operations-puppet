#
# mediawiki
#
mediawiki_memcached_servers:
  - '10.64.0.180:11211:1 "shard01"'
  - '10.64.0.181:11211:1 "shard02"'
  - '10.64.0.182:11211:1 "shard03"'
  - '10.64.0.183:11211:1 "shard04"'
  - '10.64.0.184:11211:1 "shard05"'
  - '10.64.0.185:11211:1 "shard06"'
  - '10.64.32.161:11211:1 "shard07"'
  - '10.64.32.162:11211:1 "shard08"'
  - '10.64.32.163:11211:1 "shard09"'
  - '10.64.32.164:11211:1 "shard10"'
  - '10.64.32.165:11211:1 "shard11"'
  - '10.64.32.166:11211:1 "shard12"'
  - '10.64.48.101:11211:1 "shard13"'
  - '10.64.48.102:11211:1 "shard14"'
  - '10.64.48.103:11211:1 "shard15"'
  - '10.64.48.104:11211:1 "shard16"'
  - '10.64.48.95:11211:1 "shard17"'
  - '10.64.48.96:11211:1 "shard18"'

#
# Ganglia
#
ganglia_aggregators: carbon.wikimedia.org:9649

# Eventlogging
eventlogging_host: 10.64.32.167 # eventlog1001

# Kafka Topic eventlogging-client-side with
# raw eventlogging events has 12 partitions
# in production.  Run 12 processors.
eventlogging_client_side_processors:
    - client-side-00
    - client-side-01
    - client-side-02
    - client-side-03
    - client-side-04
    - client-side-05
    - client-side-06
    - client-side-07
    - client-side-08
    - client-side-09
    - client-side-10
    - client-side-11

# Kafka Topic eventlogging-valid-mixed with
# most eventlogging events has 12 partitions
# in production.  Run 4 mysql consumers
# to insert this data into the log database.
eventlogging_mysql_consumers:
    - mysql-m4-master-00
    # Dropping these consumers because custom replication of
    # eventlogging tables does not work with parallel consumers due to
    # race conditions. We'll bring these back after adding autoincrement ids
    # to eventlogging tables, and having replication script check the ids
    # instead of the time based faulty checking for new events that's happening now.
    # - mysql-m4-master-01
    # - mysql-m4-master-02
    # - mysql-m4-master-03


labs_certmanager_hostname: "labservices1001.wikimedia.org"

# This can be used by clients that need to connect to etcd.
# Unfortunetly it is hardcoded here.
etcd_hosts:
    - conf1001.eqiad.wmnet
    - conf1002.eqiad.wmnet
    - conf1003.eqiad.wmnet

# List of Zookeeper service nodes in eqiad and their ids.
zookeeper_hosts:
  conf1001.eqiad.wmnet: '1101'
  conf1002.eqiad.wmnet: '1102'
  conf1003.eqiad.wmnet: '1103'

#
# Labs
#

labs_nova_controller: &labsnovacontroller "labcontrol1001.wikimedia.org"
# _spare is a duplicate/backup controller.  In theory it has the
#  same state as the main controller.
# WARNING:  Base images are rsynced from the primary host to the spare with
#  --delete.  Make sure to back-up or otherwise keep track
#  of your base images before creating a new empty, primary host here or
#  you'll lose your image backups.
labs_nova_controller_spare: &labsnovacontrollerspare "labcontrol1002.wikimedia.org"

labs_glance_controller: &labsglancecontroller "labcontrol1001.wikimedia.org"
labs_puppet_master: &labspuppetmaster "labs-puppetmaster-eqiad.wikimedia.org"
labs_keystone_host: &labskeystonehost "labcontrol1001.wikimedia.org"

labs_osm_host: "wikitech.wikimedia.org"
labs_horizon_host: "californium.wikimedia.org"

# These are the up-and-coming, better dns servers:
labsdnsconfig:
  host: 'labs-ns0.wikimedia.org'
  host_secondary: 'labs-ns1.wikimedia.org'
  dbserver: 'localhost'
  recursor: 'labs-recursor1.wikimedia.org'
  recursor_secondary: 'labs-recursor0.wikimedia.org'

novaconfig:
  db_host: 'm5-master.eqiad.wmnet'
  glance_host: *labsnovacontroller
  rabbit_host: *labsnovacontroller
  cc_host: *labsnovacontroller
  site_address: '208.80.155.255'
  controller_hostname: *labsnovacontroller
  ldap_host: *labsnovacontroller
  puppet_host: *labsnovacontroller
  puppet_db_host: *labsnovacontroller
  dhcp_domain: 'eqiad.wmflabs'
  live_migration_uri: 'qemu://%s.eqiad.wmnet/system?pkipath=/var/lib/nova'
  zone: eqiad
  scheduler_pool:
    - labvirt1001
    - labvirt1002
    - labvirt1003
    - labvirt1004
    - labvirt1005
    - labvirt1006
    - labvirt1007
    - labvirt1008
    - labvirt1009
    - labvirt1010

keystoneconfig:
  auth_port: '35357'
  auth_protocol: 'http'
  auth_host: 208.80.154.92
  admin_project_id: 'admin'
  admin_project_name: 'admin'
  oath_dbname: 'labswiki'
  oath_dbhost: 'silver.wikimedia.org'

designateconfig:
  db_host:  'm5-master.eqiad.wmnet'
  db_name: 'designate'
  pool_manager_db_name: 'designate_pool_manager'
  dhcp_domain: 'eqiad'
  pdns_db_name: 'pdns'
  rabbit_host:  *labsnovacontroller
  controller_hostname: *labsnovacontroller
  domain_id_internal_forward: '114f1333-c2c1-44d3-beb4-ebed1a91742b'
  domain_id_internal_reverse: '8d114f3c-815b-466c-bdd4-9b91f704ea60'
  wmflabsdotorg_project: 'wmflabsdotorg'

labs_baremetal_servers:
  - '10.64.20.12'

ldap_labs_hostname: ldap-labs.eqiad.wikimedia.org

# Configure regular backups of the analytics-meta MySQL instance
# in the Analytics Cluster to back up via rsync to
# analytics1002.  This works because the analytics1002 has the
# role::analyitcs_cluster::database::meta::backup_dest class
# applied to it.
analytics_cluster_meta_database_backup_rsync_dest: analytics1002.eqiad.wmnet::backup/mysql/analytics-meta
